{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "pd.set_option('display.max_columns', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_models(model, X_train, y_train, X_val, y_val, verbose = True):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    \n",
    "    score = cross_val_score(model, X_train, y_train, cv = 5, scoring = 'accuracy', n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_val)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_hat).ravel()\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    if(verbose):\n",
    "        print('======== Score Report =======')\n",
    "        print('')\n",
    "        print(f'Model: {type(model)}')\n",
    "        print(f'Params: {model.get_params()}')\n",
    "\n",
    "        print('')\n",
    "        print('******** Cross-Validation Scores ********')\n",
    "        print(f'Mean 5-fold CV accuracy: {score.mean()}')\n",
    "\n",
    "        print(' ')\n",
    "\n",
    "        print('******** Test/Validation Scores ********')\n",
    "        print(f'True Positives: {tp}')\n",
    "        print(f'True Negatives: {tn}')\n",
    "        print(f'False Positives: {fp}')\n",
    "        print(f'False Negatives: {fn}')\n",
    "        print('')\n",
    "        print('')\n",
    "\n",
    "        print(f'Accuracy: {model.score(X_val, y_val)}')\n",
    "        print(f'Sensitivity/Recall (TPR): {recall}')\n",
    "        print(f'Specificity (TNR): {tn/(tn+fp)}')\n",
    "        print(f'Precision: {precision}')\n",
    "        print(f'F1 Score: {2*(precision*recall)/(precision+recall)}')\n",
    "        print('')      \n",
    "        print('======================')\n",
    "        print('')   \n",
    "    \n",
    "    return {'train_score' : model.score(X_train, y_train), 'cv_score': score.mean(), 'test_score': model.score(X_val, y_val), \n",
    "            'tn': tn, 'tp': tp, 'fn': fn, 'fp':fp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = [ 'math', 'physics']\n",
    "\n",
    "subreddit_dir = f'./{subreddits[0]}_{subreddits[1]}_data/'\n",
    "\n",
    "df = pd.read_csv(f'{subreddit_dir}{subreddits[0]}_{subreddits[1]}_combined_lem_stem2.csv', keep_default_na = False)\n",
    "#df = df.sample(n = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>text</th>\n",
       "      <th>lem_text</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>undecidability decidability help</td>\n",
       "      <td>hello looking somebody experienced undecidabil...</td>\n",
       "      <td>undecidability decidability help hello looking...</td>\n",
       "      <td>undecidability decidability help hello looking...</td>\n",
       "      <td>undecid decid help hello look somebodi experie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probability</td>\n",
       "      <td>okay game get hooked chance getting tries get ...</td>\n",
       "      <td>probability okay game get hooked chance gettin...</td>\n",
       "      <td>probability okay game get hooked chance gettin...</td>\n",
       "      <td>probabl okay game get hook chanc get tri get q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anyone else feel though current prodigy cultur...</td>\n",
       "      <td>whenever talk people mathematics seems like ev...</td>\n",
       "      <td>anyone else feel though current prodigy cultur...</td>\n",
       "      <td>anyone else feel though current prodigy cultur...</td>\n",
       "      <td>anyon els feel though current prodigi cultur i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>infinite always equal another infinite</td>\n",
       "      <td>let say infinite number boxes front red ball i...</td>\n",
       "      <td>infinite always equal another infinite let say...</td>\n",
       "      <td>infinite always equal another infinite let say...</td>\n",
       "      <td>infinit alway equal anoth infinit let say infi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unit something thousand</td>\n",
       "      <td></td>\n",
       "      <td>unit something thousand</td>\n",
       "      <td>unit something thousand</td>\n",
       "      <td>unit someth thousand</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                   undecidability decidability help   \n",
       "1                                        probability   \n",
       "2  anyone else feel though current prodigy cultur...   \n",
       "3             infinite always equal another infinite   \n",
       "4                            unit something thousand   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  hello looking somebody experienced undecidabil...   \n",
       "1  okay game get hooked chance getting tries get ...   \n",
       "2  whenever talk people mathematics seems like ev...   \n",
       "3  let say infinite number boxes front red ball i...   \n",
       "4                                                      \n",
       "\n",
       "                                                text  \\\n",
       "0  undecidability decidability help hello looking...   \n",
       "1  probability okay game get hooked chance gettin...   \n",
       "2  anyone else feel though current prodigy cultur...   \n",
       "3  infinite always equal another infinite let say...   \n",
       "4                           unit something thousand    \n",
       "\n",
       "                                            lem_text  \\\n",
       "0  undecidability decidability help hello looking...   \n",
       "1  probability okay game get hooked chance gettin...   \n",
       "2  anyone else feel though current prodigy cultur...   \n",
       "3  infinite always equal another infinite let say...   \n",
       "4                            unit something thousand   \n",
       "\n",
       "                                           stem_text  subreddit  \n",
       "0  undecid decid help hello look somebodi experie...          0  \n",
       "1  probabl okay game get hook chanc get tri get q...          0  \n",
       "2  anyon els feel though current prodigi cultur i...          0  \n",
       "3  infinit alway equal anoth infinit let say infi...          0  \n",
       "4                               unit someth thousand          0  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3596, 6)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['lem_text']\n",
    "y = df['subreddit']\n",
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X,y,random_state = 42, stratify = y, test_size = test_size)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state = 42, stratify = y_train_val, test_size = val_size/(1-test_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884.6"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]*.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(885,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(885,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.500942\n",
       "1    0.499058\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline scores\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "nb = MultinomialNB()\n",
    "logreg = LogisticRegression()\n",
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    "bag = BaggingClassifier(random_state = 42)\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "et  = ExtraTreesClassifier(random_state = 42)\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "gboost = GradientBoostingClassifier()\n",
    "svc = SVC(gamma=\"scale\")\n",
    "\n",
    "models = [('knn', knn), ('nb',nb), ('logreg', logreg), ('cart', dt), \n",
    "          ('bagging',bag) , ('randomforest', rf),('extratree', et),\n",
    "          ('adaboost',ada),('gradientboost', gboost), ('svm',svc)]\n",
    "cvec = CountVectorizer()\n",
    "cvec.fit(X_train)\n",
    "scores = []\n",
    "for model_pair in models: \n",
    "    model = model_pair[1]\n",
    "    score = {}\n",
    "    score['model'] = model_pair[0]\n",
    "    score.update(eval_models(model, cvec.transform(X_train), y_train, cvec.transform(X_val), y_val, verbose = False))\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_scores = pd.DataFrame(scores).sort_values('test_score', ascending = False)\n",
    "default_scores['vect'] = 'cvec, ngram_range = (1,1)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "nb = MultinomialNB()\n",
    "logreg = LogisticRegression()\n",
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    "bag = BaggingClassifier(random_state = 42)\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "et  = ExtraTreesClassifier(random_state = 42)\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "gboost = GradientBoostingClassifier()\n",
    "svc = SVC(gamma=\"scale\")\n",
    "\n",
    "models = [('knn', knn), ('nb',nb), ('logreg', logreg), ('cart', dt), \n",
    "          ('bagging',bag) , ('randomforest', rf),('extratree', et),\n",
    "          ('adaboost',ada),('gradientboost', gboost), ('svm',svc)]\n",
    "cvec = CountVectorizer(ngram_range = (1,2))\n",
    "cvec.fit(X_train)\n",
    "scores = []\n",
    "for model_pair in models: \n",
    "    model = model_pair[1]\n",
    "    score = {}\n",
    "    score['model'] = model_pair[0]\n",
    "    score.update(eval_models(model, cvec.transform(X_train), y_train, cvec.transform(X_val), y_val, verbose = False))\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>vect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.990200</td>\n",
       "      <td>0.897099</td>\n",
       "      <td>0.906215</td>\n",
       "      <td>415</td>\n",
       "      <td>387</td>\n",
       "      <td>54</td>\n",
       "      <td>29</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.956653</td>\n",
       "      <td>0.898604</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>402</td>\n",
       "      <td>393</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.997361</td>\n",
       "      <td>0.869950</td>\n",
       "      <td>0.884746</td>\n",
       "      <td>371</td>\n",
       "      <td>412</td>\n",
       "      <td>29</td>\n",
       "      <td>73</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.992838</td>\n",
       "      <td>0.869948</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>369</td>\n",
       "      <td>411</td>\n",
       "      <td>30</td>\n",
       "      <td>75</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.852244</td>\n",
       "      <td>0.871186</td>\n",
       "      <td>407</td>\n",
       "      <td>364</td>\n",
       "      <td>77</td>\n",
       "      <td>37</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>extratree</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.840569</td>\n",
       "      <td>0.871186</td>\n",
       "      <td>409</td>\n",
       "      <td>362</td>\n",
       "      <td>79</td>\n",
       "      <td>35</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.845462</td>\n",
       "      <td>0.851977</td>\n",
       "      <td>391</td>\n",
       "      <td>363</td>\n",
       "      <td>78</td>\n",
       "      <td>53</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>extratree</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.832652</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>396</td>\n",
       "      <td>354</td>\n",
       "      <td>87</td>\n",
       "      <td>48</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gradientboost</td>\n",
       "      <td>0.888051</td>\n",
       "      <td>0.837534</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>333</td>\n",
       "      <td>412</td>\n",
       "      <td>29</td>\n",
       "      <td>111</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gradientboost</td>\n",
       "      <td>0.885790</td>\n",
       "      <td>0.840548</td>\n",
       "      <td>0.837288</td>\n",
       "      <td>329</td>\n",
       "      <td>412</td>\n",
       "      <td>29</td>\n",
       "      <td>115</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.989069</td>\n",
       "      <td>0.805873</td>\n",
       "      <td>0.833898</td>\n",
       "      <td>383</td>\n",
       "      <td>355</td>\n",
       "      <td>86</td>\n",
       "      <td>61</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.990954</td>\n",
       "      <td>0.814921</td>\n",
       "      <td>0.832768</td>\n",
       "      <td>380</td>\n",
       "      <td>357</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.794183</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>371</td>\n",
       "      <td>364</td>\n",
       "      <td>77</td>\n",
       "      <td>73</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.915567</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.828249</td>\n",
       "      <td>336</td>\n",
       "      <td>397</td>\n",
       "      <td>44</td>\n",
       "      <td>108</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.795696</td>\n",
       "      <td>0.816949</td>\n",
       "      <td>372</td>\n",
       "      <td>351</td>\n",
       "      <td>90</td>\n",
       "      <td>72</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.915190</td>\n",
       "      <td>0.797201</td>\n",
       "      <td>0.815819</td>\n",
       "      <td>318</td>\n",
       "      <td>404</td>\n",
       "      <td>37</td>\n",
       "      <td>126</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.780615</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>376</td>\n",
       "      <td>329</td>\n",
       "      <td>112</td>\n",
       "      <td>68</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.786267</td>\n",
       "      <td>0.792090</td>\n",
       "      <td>361</td>\n",
       "      <td>340</td>\n",
       "      <td>101</td>\n",
       "      <td>83</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.866943</td>\n",
       "      <td>0.708628</td>\n",
       "      <td>0.714124</td>\n",
       "      <td>289</td>\n",
       "      <td>343</td>\n",
       "      <td>98</td>\n",
       "      <td>155</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.851866</td>\n",
       "      <td>0.633988</td>\n",
       "      <td>0.659887</td>\n",
       "      <td>290</td>\n",
       "      <td>294</td>\n",
       "      <td>147</td>\n",
       "      <td>154</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  train_score  cv_score  test_score   tn   tp   fn   fp  \\\n",
       "1             nb     0.990200  0.897099    0.906215  415  387   54   29   \n",
       "1             nb     0.956653  0.898604    0.898305  402  393   48   42   \n",
       "2         logreg     0.997361  0.869950    0.884746  371  412   29   73   \n",
       "2         logreg     0.992838  0.869948    0.881356  369  411   30   75   \n",
       "5   randomforest     0.999623  0.852244    0.871186  407  364   77   37   \n",
       "6      extratree     0.999623  0.840569    0.871186  409  362   79   35   \n",
       "5   randomforest     0.999623  0.845462    0.851977  391  363   78   53   \n",
       "6      extratree     0.999623  0.832652    0.847458  396  354   87   48   \n",
       "8  gradientboost     0.888051  0.837534    0.841808  333  412   29  111   \n",
       "8  gradientboost     0.885790  0.840548    0.837288  329  412   29  115   \n",
       "4        bagging     0.989069  0.805873    0.833898  383  355   86   61   \n",
       "4        bagging     0.990954  0.814921    0.832768  380  357   84   64   \n",
       "7       adaboost     0.999623  0.794183    0.830508  371  364   77   73   \n",
       "9            svm     0.915567  0.813031    0.828249  336  397   44  108   \n",
       "7       adaboost     0.999623  0.795696    0.816949  372  351   90   72   \n",
       "9            svm     0.915190  0.797201    0.815819  318  404   37  126   \n",
       "3           cart     0.999623  0.780615    0.796610  376  329  112   68   \n",
       "3           cart     0.999623  0.786267    0.792090  361  340  101   83   \n",
       "0            knn     0.866943  0.708628    0.714124  289  343   98  155   \n",
       "0            knn     0.851866  0.633988    0.659887  290  294  147  154   \n",
       "\n",
       "                        vect  \n",
       "1  cvec, ngram_range = (1,2)  \n",
       "1  cvec, ngram_range = (1,1)  \n",
       "2  cvec, ngram_range = (1,2)  \n",
       "2  cvec, ngram_range = (1,1)  \n",
       "5  cvec, ngram_range = (1,1)  \n",
       "6  cvec, ngram_range = (1,1)  \n",
       "5  cvec, ngram_range = (1,2)  \n",
       "6  cvec, ngram_range = (1,2)  \n",
       "8  cvec, ngram_range = (1,2)  \n",
       "8  cvec, ngram_range = (1,1)  \n",
       "4  cvec, ngram_range = (1,1)  \n",
       "4  cvec, ngram_range = (1,2)  \n",
       "7  cvec, ngram_range = (1,1)  \n",
       "9  cvec, ngram_range = (1,1)  \n",
       "7  cvec, ngram_range = (1,2)  \n",
       "9  cvec, ngram_range = (1,2)  \n",
       "3  cvec, ngram_range = (1,2)  \n",
       "3  cvec, ngram_range = (1,1)  \n",
       "0  cvec, ngram_range = (1,1)  \n",
       "0  cvec, ngram_range = (1,2)  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame(scores)\n",
    "temp['vect'] = 'cvec, ngram_range = (1,2)'\n",
    "default_scores = pd.concat([default_scores, temp], axis = 0)\n",
    "default_scores.sort_values('test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "nb = MultinomialNB()\n",
    "logreg = LogisticRegression()\n",
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    "bag = BaggingClassifier(random_state = 42)\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "et  = ExtraTreesClassifier(random_state = 42)\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "gboost = GradientBoostingClassifier()\n",
    "svc = SVC(gamma=\"scale\")\n",
    "\n",
    "models = [('knn', knn), ('nb',nb), ('logreg', logreg), ('cart', dt), \n",
    "          ('bagging',bag) , ('randomforest', rf),('extratree', et),\n",
    "          ('adaboost',ada),('gradientboost', gboost), ('svm',svc)]\n",
    "tvec = TfidfVectorizer()\n",
    "tvec.fit(X_train)\n",
    "scores = []\n",
    "for model_pair in models: \n",
    "    model = model_pair[1]\n",
    "    score = {}\n",
    "    score['model'] = model_pair[0]\n",
    "    score.update(eval_models(model, tvec.transform(X_train), y_train, tvec.transform(X_val), y_val, verbose = False))\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>vect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.990200</td>\n",
       "      <td>0.897099</td>\n",
       "      <td>0.906215</td>\n",
       "      <td>415</td>\n",
       "      <td>387</td>\n",
       "      <td>54</td>\n",
       "      <td>29</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.996231</td>\n",
       "      <td>0.895964</td>\n",
       "      <td>0.902825</td>\n",
       "      <td>391</td>\n",
       "      <td>408</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.973238</td>\n",
       "      <td>0.894836</td>\n",
       "      <td>0.901695</td>\n",
       "      <td>388</td>\n",
       "      <td>410</td>\n",
       "      <td>31</td>\n",
       "      <td>56</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.956653</td>\n",
       "      <td>0.898604</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>402</td>\n",
       "      <td>393</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.997361</td>\n",
       "      <td>0.869950</td>\n",
       "      <td>0.884746</td>\n",
       "      <td>371</td>\n",
       "      <td>412</td>\n",
       "      <td>29</td>\n",
       "      <td>73</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.992838</td>\n",
       "      <td>0.869948</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>369</td>\n",
       "      <td>411</td>\n",
       "      <td>30</td>\n",
       "      <td>75</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>extratree</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.854885</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>407</td>\n",
       "      <td>368</td>\n",
       "      <td>73</td>\n",
       "      <td>37</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.854510</td>\n",
       "      <td>0.872316</td>\n",
       "      <td>410</td>\n",
       "      <td>362</td>\n",
       "      <td>79</td>\n",
       "      <td>34</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.852244</td>\n",
       "      <td>0.871186</td>\n",
       "      <td>407</td>\n",
       "      <td>364</td>\n",
       "      <td>77</td>\n",
       "      <td>37</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>extratree</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.840569</td>\n",
       "      <td>0.871186</td>\n",
       "      <td>409</td>\n",
       "      <td>362</td>\n",
       "      <td>79</td>\n",
       "      <td>35</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.955522</td>\n",
       "      <td>0.879760</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>416</td>\n",
       "      <td>354</td>\n",
       "      <td>87</td>\n",
       "      <td>28</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.845462</td>\n",
       "      <td>0.851977</td>\n",
       "      <td>391</td>\n",
       "      <td>363</td>\n",
       "      <td>78</td>\n",
       "      <td>53</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>extratree</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.832652</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>396</td>\n",
       "      <td>354</td>\n",
       "      <td>87</td>\n",
       "      <td>48</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gradientboost</td>\n",
       "      <td>0.888051</td>\n",
       "      <td>0.837534</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>333</td>\n",
       "      <td>412</td>\n",
       "      <td>29</td>\n",
       "      <td>111</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gradientboost</td>\n",
       "      <td>0.885790</td>\n",
       "      <td>0.840548</td>\n",
       "      <td>0.837288</td>\n",
       "      <td>329</td>\n",
       "      <td>412</td>\n",
       "      <td>29</td>\n",
       "      <td>115</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.989069</td>\n",
       "      <td>0.805873</td>\n",
       "      <td>0.833898</td>\n",
       "      <td>383</td>\n",
       "      <td>355</td>\n",
       "      <td>86</td>\n",
       "      <td>61</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.990954</td>\n",
       "      <td>0.814921</td>\n",
       "      <td>0.832768</td>\n",
       "      <td>380</td>\n",
       "      <td>357</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.989069</td>\n",
       "      <td>0.807008</td>\n",
       "      <td>0.831638</td>\n",
       "      <td>389</td>\n",
       "      <td>347</td>\n",
       "      <td>94</td>\n",
       "      <td>55</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.794183</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>371</td>\n",
       "      <td>364</td>\n",
       "      <td>77</td>\n",
       "      <td>73</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.915567</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.828249</td>\n",
       "      <td>336</td>\n",
       "      <td>397</td>\n",
       "      <td>44</td>\n",
       "      <td>108</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gradientboost</td>\n",
       "      <td>0.900490</td>\n",
       "      <td>0.836773</td>\n",
       "      <td>0.827119</td>\n",
       "      <td>322</td>\n",
       "      <td>410</td>\n",
       "      <td>31</td>\n",
       "      <td>122</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.797582</td>\n",
       "      <td>0.818079</td>\n",
       "      <td>377</td>\n",
       "      <td>347</td>\n",
       "      <td>94</td>\n",
       "      <td>67</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.795696</td>\n",
       "      <td>0.816949</td>\n",
       "      <td>372</td>\n",
       "      <td>351</td>\n",
       "      <td>90</td>\n",
       "      <td>72</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.915190</td>\n",
       "      <td>0.797201</td>\n",
       "      <td>0.815819</td>\n",
       "      <td>318</td>\n",
       "      <td>404</td>\n",
       "      <td>37</td>\n",
       "      <td>126</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.780615</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>376</td>\n",
       "      <td>329</td>\n",
       "      <td>112</td>\n",
       "      <td>68</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.779866</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>370</td>\n",
       "      <td>335</td>\n",
       "      <td>106</td>\n",
       "      <td>74</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.786267</td>\n",
       "      <td>0.792090</td>\n",
       "      <td>361</td>\n",
       "      <td>340</td>\n",
       "      <td>101</td>\n",
       "      <td>83</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.902752</td>\n",
       "      <td>0.788551</td>\n",
       "      <td>0.784181</td>\n",
       "      <td>395</td>\n",
       "      <td>299</td>\n",
       "      <td>142</td>\n",
       "      <td>49</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.866943</td>\n",
       "      <td>0.708628</td>\n",
       "      <td>0.714124</td>\n",
       "      <td>289</td>\n",
       "      <td>343</td>\n",
       "      <td>98</td>\n",
       "      <td>155</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.851866</td>\n",
       "      <td>0.633988</td>\n",
       "      <td>0.659887</td>\n",
       "      <td>290</td>\n",
       "      <td>294</td>\n",
       "      <td>147</td>\n",
       "      <td>154</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  train_score  cv_score  test_score   tn   tp   fn   fp  \\\n",
       "1             nb     0.990200  0.897099    0.906215  415  387   54   29   \n",
       "9            svm     0.996231  0.895964    0.902825  391  408   33   53   \n",
       "2         logreg     0.973238  0.894836    0.901695  388  410   31   56   \n",
       "1             nb     0.956653  0.898604    0.898305  402  393   48   42   \n",
       "2         logreg     0.997361  0.869950    0.884746  371  412   29   73   \n",
       "2         logreg     0.992838  0.869948    0.881356  369  411   30   75   \n",
       "6      extratree     0.999623  0.854885    0.875706  407  368   73   37   \n",
       "5   randomforest     0.999623  0.854510    0.872316  410  362   79   34   \n",
       "5   randomforest     0.999623  0.852244    0.871186  407  364   77   37   \n",
       "6      extratree     0.999623  0.840569    0.871186  409  362   79   35   \n",
       "1             nb     0.955522  0.879760    0.870056  416  354   87   28   \n",
       "5   randomforest     0.999623  0.845462    0.851977  391  363   78   53   \n",
       "6      extratree     0.999623  0.832652    0.847458  396  354   87   48   \n",
       "8  gradientboost     0.888051  0.837534    0.841808  333  412   29  111   \n",
       "8  gradientboost     0.885790  0.840548    0.837288  329  412   29  115   \n",
       "4        bagging     0.989069  0.805873    0.833898  383  355   86   61   \n",
       "4        bagging     0.990954  0.814921    0.832768  380  357   84   64   \n",
       "4        bagging     0.989069  0.807008    0.831638  389  347   94   55   \n",
       "7       adaboost     0.999623  0.794183    0.830508  371  364   77   73   \n",
       "9            svm     0.915567  0.813031    0.828249  336  397   44  108   \n",
       "8  gradientboost     0.900490  0.836773    0.827119  322  410   31  122   \n",
       "7       adaboost     0.999623  0.797582    0.818079  377  347   94   67   \n",
       "7       adaboost     0.999623  0.795696    0.816949  372  351   90   72   \n",
       "9            svm     0.915190  0.797201    0.815819  318  404   37  126   \n",
       "3           cart     0.999623  0.780615    0.796610  376  329  112   68   \n",
       "3           cart     0.999623  0.779866    0.796610  370  335  106   74   \n",
       "3           cart     0.999623  0.786267    0.792090  361  340  101   83   \n",
       "0            knn     0.902752  0.788551    0.784181  395  299  142   49   \n",
       "0            knn     0.866943  0.708628    0.714124  289  343   98  155   \n",
       "0            knn     0.851866  0.633988    0.659887  290  294  147  154   \n",
       "\n",
       "                        vect  \n",
       "1  cvec, ngram_range = (1,2)  \n",
       "9  tvec, ngram_range = (1,1)  \n",
       "2  tvec, ngram_range = (1,1)  \n",
       "1  cvec, ngram_range = (1,1)  \n",
       "2  cvec, ngram_range = (1,2)  \n",
       "2  cvec, ngram_range = (1,1)  \n",
       "6  tvec, ngram_range = (1,1)  \n",
       "5  tvec, ngram_range = (1,1)  \n",
       "5  cvec, ngram_range = (1,1)  \n",
       "6  cvec, ngram_range = (1,1)  \n",
       "1  tvec, ngram_range = (1,1)  \n",
       "5  cvec, ngram_range = (1,2)  \n",
       "6  cvec, ngram_range = (1,2)  \n",
       "8  cvec, ngram_range = (1,2)  \n",
       "8  cvec, ngram_range = (1,1)  \n",
       "4  cvec, ngram_range = (1,1)  \n",
       "4  cvec, ngram_range = (1,2)  \n",
       "4  tvec, ngram_range = (1,1)  \n",
       "7  cvec, ngram_range = (1,1)  \n",
       "9  cvec, ngram_range = (1,1)  \n",
       "8  tvec, ngram_range = (1,1)  \n",
       "7  tvec, ngram_range = (1,1)  \n",
       "7  cvec, ngram_range = (1,2)  \n",
       "9  cvec, ngram_range = (1,2)  \n",
       "3  cvec, ngram_range = (1,2)  \n",
       "3  tvec, ngram_range = (1,1)  \n",
       "3  cvec, ngram_range = (1,1)  \n",
       "0  tvec, ngram_range = (1,1)  \n",
       "0  cvec, ngram_range = (1,1)  \n",
       "0  cvec, ngram_range = (1,2)  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame(scores)\n",
    "temp['vect'] = 'tvec, ngram_range = (1,1)'\n",
    "default_scores = pd.concat([default_scores, temp], axis = 0)\n",
    "default_scores.sort_values('test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "nb = MultinomialNB()\n",
    "logreg = LogisticRegression()\n",
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    "bag = BaggingClassifier(random_state = 42)\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "et  = ExtraTreesClassifier(random_state = 42)\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "gboost = GradientBoostingClassifier()\n",
    "svc = SVC(gamma=\"scale\")\n",
    "\n",
    "models = [('knn', knn), ('nb',nb), ('logreg', logreg), ('cart', dt), \n",
    "          ('bagging',bag) , ('randomforest', rf),('extratree', et),\n",
    "          ('adaboost',ada),('gradientboost', gboost), ('svm',svc)]\n",
    "tvec = TfidfVectorizer(ngram_range = (1,2))\n",
    "tvec.fit(X_train)\n",
    "scores = []\n",
    "for model_pair in models: \n",
    "    model = model_pair[1]\n",
    "    score = {}\n",
    "    score['model'] = model_pair[0]\n",
    "    score.update(eval_models(model, tvec.transform(X_train), y_train, tvec.transform(X_val), y_val, verbose = False))\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>vect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.990200</td>\n",
       "      <td>0.897099</td>\n",
       "      <td>0.906215</td>\n",
       "      <td>415</td>\n",
       "      <td>387</td>\n",
       "      <td>54</td>\n",
       "      <td>29</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.895590</td>\n",
       "      <td>0.905085</td>\n",
       "      <td>401</td>\n",
       "      <td>400</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.990200</td>\n",
       "      <td>0.891065</td>\n",
       "      <td>0.905085</td>\n",
       "      <td>401</td>\n",
       "      <td>400</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.996231</td>\n",
       "      <td>0.895964</td>\n",
       "      <td>0.902825</td>\n",
       "      <td>391</td>\n",
       "      <td>408</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.973238</td>\n",
       "      <td>0.894836</td>\n",
       "      <td>0.901695</td>\n",
       "      <td>388</td>\n",
       "      <td>410</td>\n",
       "      <td>31</td>\n",
       "      <td>56</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.956653</td>\n",
       "      <td>0.898604</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>402</td>\n",
       "      <td>393</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.997361</td>\n",
       "      <td>0.869950</td>\n",
       "      <td>0.884746</td>\n",
       "      <td>371</td>\n",
       "      <td>412</td>\n",
       "      <td>29</td>\n",
       "      <td>73</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.992838</td>\n",
       "      <td>0.869948</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>369</td>\n",
       "      <td>411</td>\n",
       "      <td>30</td>\n",
       "      <td>75</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.991708</td>\n",
       "      <td>0.883908</td>\n",
       "      <td>0.877966</td>\n",
       "      <td>420</td>\n",
       "      <td>357</td>\n",
       "      <td>84</td>\n",
       "      <td>24</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>extratree</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.854885</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>407</td>\n",
       "      <td>368</td>\n",
       "      <td>73</td>\n",
       "      <td>37</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.854510</td>\n",
       "      <td>0.872316</td>\n",
       "      <td>410</td>\n",
       "      <td>362</td>\n",
       "      <td>79</td>\n",
       "      <td>34</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>extratree</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.840569</td>\n",
       "      <td>0.871186</td>\n",
       "      <td>409</td>\n",
       "      <td>362</td>\n",
       "      <td>79</td>\n",
       "      <td>35</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.852244</td>\n",
       "      <td>0.871186</td>\n",
       "      <td>407</td>\n",
       "      <td>364</td>\n",
       "      <td>77</td>\n",
       "      <td>37</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.955522</td>\n",
       "      <td>0.879760</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>416</td>\n",
       "      <td>354</td>\n",
       "      <td>87</td>\n",
       "      <td>28</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>extratree</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.848863</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>401</td>\n",
       "      <td>359</td>\n",
       "      <td>82</td>\n",
       "      <td>43</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.845462</td>\n",
       "      <td>0.851977</td>\n",
       "      <td>391</td>\n",
       "      <td>363</td>\n",
       "      <td>78</td>\n",
       "      <td>53</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>extratree</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.832652</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>396</td>\n",
       "      <td>354</td>\n",
       "      <td>87</td>\n",
       "      <td>48</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.835283</td>\n",
       "      <td>0.844068</td>\n",
       "      <td>401</td>\n",
       "      <td>346</td>\n",
       "      <td>95</td>\n",
       "      <td>43</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gradientboost</td>\n",
       "      <td>0.888051</td>\n",
       "      <td>0.837534</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>333</td>\n",
       "      <td>412</td>\n",
       "      <td>29</td>\n",
       "      <td>111</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gradientboost</td>\n",
       "      <td>0.885790</td>\n",
       "      <td>0.840548</td>\n",
       "      <td>0.837288</td>\n",
       "      <td>329</td>\n",
       "      <td>412</td>\n",
       "      <td>29</td>\n",
       "      <td>115</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gradientboost</td>\n",
       "      <td>0.904259</td>\n",
       "      <td>0.832632</td>\n",
       "      <td>0.836158</td>\n",
       "      <td>333</td>\n",
       "      <td>407</td>\n",
       "      <td>34</td>\n",
       "      <td>111</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.989069</td>\n",
       "      <td>0.805873</td>\n",
       "      <td>0.833898</td>\n",
       "      <td>383</td>\n",
       "      <td>355</td>\n",
       "      <td>86</td>\n",
       "      <td>61</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.990954</td>\n",
       "      <td>0.814921</td>\n",
       "      <td>0.832768</td>\n",
       "      <td>380</td>\n",
       "      <td>357</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.989069</td>\n",
       "      <td>0.807008</td>\n",
       "      <td>0.831638</td>\n",
       "      <td>389</td>\n",
       "      <td>347</td>\n",
       "      <td>94</td>\n",
       "      <td>55</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.794183</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>371</td>\n",
       "      <td>364</td>\n",
       "      <td>77</td>\n",
       "      <td>73</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.915567</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.828249</td>\n",
       "      <td>336</td>\n",
       "      <td>397</td>\n",
       "      <td>44</td>\n",
       "      <td>108</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gradientboost</td>\n",
       "      <td>0.900490</td>\n",
       "      <td>0.836773</td>\n",
       "      <td>0.827119</td>\n",
       "      <td>322</td>\n",
       "      <td>410</td>\n",
       "      <td>31</td>\n",
       "      <td>122</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.797582</td>\n",
       "      <td>0.818079</td>\n",
       "      <td>377</td>\n",
       "      <td>347</td>\n",
       "      <td>94</td>\n",
       "      <td>67</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.991331</td>\n",
       "      <td>0.804749</td>\n",
       "      <td>0.816949</td>\n",
       "      <td>392</td>\n",
       "      <td>331</td>\n",
       "      <td>110</td>\n",
       "      <td>52</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.795696</td>\n",
       "      <td>0.816949</td>\n",
       "      <td>372</td>\n",
       "      <td>351</td>\n",
       "      <td>90</td>\n",
       "      <td>72</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.915190</td>\n",
       "      <td>0.797201</td>\n",
       "      <td>0.815819</td>\n",
       "      <td>318</td>\n",
       "      <td>404</td>\n",
       "      <td>37</td>\n",
       "      <td>126</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.793440</td>\n",
       "      <td>0.810169</td>\n",
       "      <td>377</td>\n",
       "      <td>340</td>\n",
       "      <td>101</td>\n",
       "      <td>67</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.780615</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>376</td>\n",
       "      <td>329</td>\n",
       "      <td>112</td>\n",
       "      <td>68</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.779866</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>370</td>\n",
       "      <td>335</td>\n",
       "      <td>106</td>\n",
       "      <td>74</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.786267</td>\n",
       "      <td>0.792090</td>\n",
       "      <td>361</td>\n",
       "      <td>340</td>\n",
       "      <td>101</td>\n",
       "      <td>83</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.907275</td>\n",
       "      <td>0.786287</td>\n",
       "      <td>0.787571</td>\n",
       "      <td>398</td>\n",
       "      <td>299</td>\n",
       "      <td>142</td>\n",
       "      <td>46</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.902752</td>\n",
       "      <td>0.788551</td>\n",
       "      <td>0.784181</td>\n",
       "      <td>395</td>\n",
       "      <td>299</td>\n",
       "      <td>142</td>\n",
       "      <td>49</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.780240</td>\n",
       "      <td>0.772881</td>\n",
       "      <td>377</td>\n",
       "      <td>307</td>\n",
       "      <td>134</td>\n",
       "      <td>67</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.866943</td>\n",
       "      <td>0.708628</td>\n",
       "      <td>0.714124</td>\n",
       "      <td>289</td>\n",
       "      <td>343</td>\n",
       "      <td>98</td>\n",
       "      <td>155</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.851866</td>\n",
       "      <td>0.633988</td>\n",
       "      <td>0.659887</td>\n",
       "      <td>290</td>\n",
       "      <td>294</td>\n",
       "      <td>147</td>\n",
       "      <td>154</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  train_score  cv_score  test_score   tn   tp   fn   fp  \\\n",
       "1             nb     0.990200  0.897099    0.906215  415  387   54   29   \n",
       "9            svm     0.998869  0.895590    0.905085  401  400   41   43   \n",
       "2         logreg     0.990200  0.891065    0.905085  401  400   41   43   \n",
       "9            svm     0.996231  0.895964    0.902825  391  408   33   53   \n",
       "2         logreg     0.973238  0.894836    0.901695  388  410   31   56   \n",
       "1             nb     0.956653  0.898604    0.898305  402  393   48   42   \n",
       "2         logreg     0.997361  0.869950    0.884746  371  412   29   73   \n",
       "2         logreg     0.992838  0.869948    0.881356  369  411   30   75   \n",
       "1             nb     0.991708  0.883908    0.877966  420  357   84   24   \n",
       "6      extratree     0.999623  0.854885    0.875706  407  368   73   37   \n",
       "5   randomforest     0.999623  0.854510    0.872316  410  362   79   34   \n",
       "6      extratree     0.999623  0.840569    0.871186  409  362   79   35   \n",
       "5   randomforest     0.999623  0.852244    0.871186  407  364   77   37   \n",
       "1             nb     0.955522  0.879760    0.870056  416  354   87   28   \n",
       "6      extratree     0.999623  0.848863    0.858757  401  359   82   43   \n",
       "5   randomforest     0.999623  0.845462    0.851977  391  363   78   53   \n",
       "6      extratree     0.999623  0.832652    0.847458  396  354   87   48   \n",
       "5   randomforest     0.999623  0.835283    0.844068  401  346   95   43   \n",
       "8  gradientboost     0.888051  0.837534    0.841808  333  412   29  111   \n",
       "8  gradientboost     0.885790  0.840548    0.837288  329  412   29  115   \n",
       "8  gradientboost     0.904259  0.832632    0.836158  333  407   34  111   \n",
       "4        bagging     0.989069  0.805873    0.833898  383  355   86   61   \n",
       "4        bagging     0.990954  0.814921    0.832768  380  357   84   64   \n",
       "4        bagging     0.989069  0.807008    0.831638  389  347   94   55   \n",
       "7       adaboost     0.999623  0.794183    0.830508  371  364   77   73   \n",
       "9            svm     0.915567  0.813031    0.828249  336  397   44  108   \n",
       "8  gradientboost     0.900490  0.836773    0.827119  322  410   31  122   \n",
       "7       adaboost     0.999623  0.797582    0.818079  377  347   94   67   \n",
       "4        bagging     0.991331  0.804749    0.816949  392  331  110   52   \n",
       "7       adaboost     0.999623  0.795696    0.816949  372  351   90   72   \n",
       "9            svm     0.915190  0.797201    0.815819  318  404   37  126   \n",
       "7       adaboost     0.999623  0.793440    0.810169  377  340  101   67   \n",
       "3           cart     0.999623  0.780615    0.796610  376  329  112   68   \n",
       "3           cart     0.999623  0.779866    0.796610  370  335  106   74   \n",
       "3           cart     0.999623  0.786267    0.792090  361  340  101   83   \n",
       "0            knn     0.907275  0.786287    0.787571  398  299  142   46   \n",
       "0            knn     0.902752  0.788551    0.784181  395  299  142   49   \n",
       "3           cart     0.999623  0.780240    0.772881  377  307  134   67   \n",
       "0            knn     0.866943  0.708628    0.714124  289  343   98  155   \n",
       "0            knn     0.851866  0.633988    0.659887  290  294  147  154   \n",
       "\n",
       "                        vect  \n",
       "1  cvec, ngram_range = (1,2)  \n",
       "9  tvec, ngram_range = (1,2)  \n",
       "2  tvec, ngram_range = (1,2)  \n",
       "9  tvec, ngram_range = (1,1)  \n",
       "2  tvec, ngram_range = (1,1)  \n",
       "1  cvec, ngram_range = (1,1)  \n",
       "2  cvec, ngram_range = (1,2)  \n",
       "2  cvec, ngram_range = (1,1)  \n",
       "1  tvec, ngram_range = (1,2)  \n",
       "6  tvec, ngram_range = (1,1)  \n",
       "5  tvec, ngram_range = (1,1)  \n",
       "6  cvec, ngram_range = (1,1)  \n",
       "5  cvec, ngram_range = (1,1)  \n",
       "1  tvec, ngram_range = (1,1)  \n",
       "6  tvec, ngram_range = (1,2)  \n",
       "5  cvec, ngram_range = (1,2)  \n",
       "6  cvec, ngram_range = (1,2)  \n",
       "5  tvec, ngram_range = (1,2)  \n",
       "8  cvec, ngram_range = (1,2)  \n",
       "8  cvec, ngram_range = (1,1)  \n",
       "8  tvec, ngram_range = (1,2)  \n",
       "4  cvec, ngram_range = (1,1)  \n",
       "4  cvec, ngram_range = (1,2)  \n",
       "4  tvec, ngram_range = (1,1)  \n",
       "7  cvec, ngram_range = (1,1)  \n",
       "9  cvec, ngram_range = (1,1)  \n",
       "8  tvec, ngram_range = (1,1)  \n",
       "7  tvec, ngram_range = (1,1)  \n",
       "4  tvec, ngram_range = (1,2)  \n",
       "7  cvec, ngram_range = (1,2)  \n",
       "9  cvec, ngram_range = (1,2)  \n",
       "7  tvec, ngram_range = (1,2)  \n",
       "3  cvec, ngram_range = (1,2)  \n",
       "3  tvec, ngram_range = (1,1)  \n",
       "3  cvec, ngram_range = (1,1)  \n",
       "0  tvec, ngram_range = (1,2)  \n",
       "0  tvec, ngram_range = (1,1)  \n",
       "3  tvec, ngram_range = (1,2)  \n",
       "0  cvec, ngram_range = (1,1)  \n",
       "0  cvec, ngram_range = (1,2)  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "temp = pd.DataFrame(scores).sort_values('test_score', ascending = False)\n",
    "temp['vect'] = 'tvec, ngram_range = (1,2)'\n",
    "default_scores = pd.concat([default_scores, temp], axis = 0)\n",
    "default_scores.sort_values('test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_scores.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_scores.drop(columns = ['train_score'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_scores = default_scores.sort_values('test_score', ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_scores.to_csv('./default_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>vect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.897099</td>\n",
       "      <td>0.906215</td>\n",
       "      <td>415</td>\n",
       "      <td>387</td>\n",
       "      <td>54</td>\n",
       "      <td>29</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.895590</td>\n",
       "      <td>0.905085</td>\n",
       "      <td>401</td>\n",
       "      <td>400</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.891065</td>\n",
       "      <td>0.905085</td>\n",
       "      <td>401</td>\n",
       "      <td>400</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.895964</td>\n",
       "      <td>0.902825</td>\n",
       "      <td>391</td>\n",
       "      <td>408</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.894836</td>\n",
       "      <td>0.901695</td>\n",
       "      <td>388</td>\n",
       "      <td>410</td>\n",
       "      <td>31</td>\n",
       "      <td>56</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.898604</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>402</td>\n",
       "      <td>393</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.869950</td>\n",
       "      <td>0.884746</td>\n",
       "      <td>371</td>\n",
       "      <td>412</td>\n",
       "      <td>29</td>\n",
       "      <td>73</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.869948</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>369</td>\n",
       "      <td>411</td>\n",
       "      <td>30</td>\n",
       "      <td>75</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.883908</td>\n",
       "      <td>0.877966</td>\n",
       "      <td>420</td>\n",
       "      <td>357</td>\n",
       "      <td>84</td>\n",
       "      <td>24</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>extratree</td>\n",
       "      <td>0.854885</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>407</td>\n",
       "      <td>368</td>\n",
       "      <td>73</td>\n",
       "      <td>37</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.854510</td>\n",
       "      <td>0.872316</td>\n",
       "      <td>410</td>\n",
       "      <td>362</td>\n",
       "      <td>79</td>\n",
       "      <td>34</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>extratree</td>\n",
       "      <td>0.840569</td>\n",
       "      <td>0.871186</td>\n",
       "      <td>409</td>\n",
       "      <td>362</td>\n",
       "      <td>79</td>\n",
       "      <td>35</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.852244</td>\n",
       "      <td>0.871186</td>\n",
       "      <td>407</td>\n",
       "      <td>364</td>\n",
       "      <td>77</td>\n",
       "      <td>37</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.879760</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>416</td>\n",
       "      <td>354</td>\n",
       "      <td>87</td>\n",
       "      <td>28</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>extratree</td>\n",
       "      <td>0.848863</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>401</td>\n",
       "      <td>359</td>\n",
       "      <td>82</td>\n",
       "      <td>43</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.845462</td>\n",
       "      <td>0.851977</td>\n",
       "      <td>391</td>\n",
       "      <td>363</td>\n",
       "      <td>78</td>\n",
       "      <td>53</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>extratree</td>\n",
       "      <td>0.832652</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>396</td>\n",
       "      <td>354</td>\n",
       "      <td>87</td>\n",
       "      <td>48</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.835283</td>\n",
       "      <td>0.844068</td>\n",
       "      <td>401</td>\n",
       "      <td>346</td>\n",
       "      <td>95</td>\n",
       "      <td>43</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gradientboost</td>\n",
       "      <td>0.837534</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>333</td>\n",
       "      <td>412</td>\n",
       "      <td>29</td>\n",
       "      <td>111</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gradientboost</td>\n",
       "      <td>0.840548</td>\n",
       "      <td>0.837288</td>\n",
       "      <td>329</td>\n",
       "      <td>412</td>\n",
       "      <td>29</td>\n",
       "      <td>115</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gradientboost</td>\n",
       "      <td>0.832632</td>\n",
       "      <td>0.836158</td>\n",
       "      <td>333</td>\n",
       "      <td>407</td>\n",
       "      <td>34</td>\n",
       "      <td>111</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.805873</td>\n",
       "      <td>0.833898</td>\n",
       "      <td>383</td>\n",
       "      <td>355</td>\n",
       "      <td>86</td>\n",
       "      <td>61</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.814921</td>\n",
       "      <td>0.832768</td>\n",
       "      <td>380</td>\n",
       "      <td>357</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.807008</td>\n",
       "      <td>0.831638</td>\n",
       "      <td>389</td>\n",
       "      <td>347</td>\n",
       "      <td>94</td>\n",
       "      <td>55</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>0.794183</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>371</td>\n",
       "      <td>364</td>\n",
       "      <td>77</td>\n",
       "      <td>73</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.828249</td>\n",
       "      <td>336</td>\n",
       "      <td>397</td>\n",
       "      <td>44</td>\n",
       "      <td>108</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gradientboost</td>\n",
       "      <td>0.836773</td>\n",
       "      <td>0.827119</td>\n",
       "      <td>322</td>\n",
       "      <td>410</td>\n",
       "      <td>31</td>\n",
       "      <td>122</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>0.797582</td>\n",
       "      <td>0.818079</td>\n",
       "      <td>377</td>\n",
       "      <td>347</td>\n",
       "      <td>94</td>\n",
       "      <td>67</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.804749</td>\n",
       "      <td>0.816949</td>\n",
       "      <td>392</td>\n",
       "      <td>331</td>\n",
       "      <td>110</td>\n",
       "      <td>52</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>0.795696</td>\n",
       "      <td>0.816949</td>\n",
       "      <td>372</td>\n",
       "      <td>351</td>\n",
       "      <td>90</td>\n",
       "      <td>72</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.797201</td>\n",
       "      <td>0.815819</td>\n",
       "      <td>318</td>\n",
       "      <td>404</td>\n",
       "      <td>37</td>\n",
       "      <td>126</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>0.793440</td>\n",
       "      <td>0.810169</td>\n",
       "      <td>377</td>\n",
       "      <td>340</td>\n",
       "      <td>101</td>\n",
       "      <td>67</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cart</td>\n",
       "      <td>0.780615</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>376</td>\n",
       "      <td>329</td>\n",
       "      <td>112</td>\n",
       "      <td>68</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cart</td>\n",
       "      <td>0.779866</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>370</td>\n",
       "      <td>335</td>\n",
       "      <td>106</td>\n",
       "      <td>74</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>cart</td>\n",
       "      <td>0.786267</td>\n",
       "      <td>0.792090</td>\n",
       "      <td>361</td>\n",
       "      <td>340</td>\n",
       "      <td>101</td>\n",
       "      <td>83</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.786287</td>\n",
       "      <td>0.787571</td>\n",
       "      <td>398</td>\n",
       "      <td>299</td>\n",
       "      <td>142</td>\n",
       "      <td>46</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.788551</td>\n",
       "      <td>0.784181</td>\n",
       "      <td>395</td>\n",
       "      <td>299</td>\n",
       "      <td>142</td>\n",
       "      <td>49</td>\n",
       "      <td>tvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>cart</td>\n",
       "      <td>0.780240</td>\n",
       "      <td>0.772881</td>\n",
       "      <td>377</td>\n",
       "      <td>307</td>\n",
       "      <td>134</td>\n",
       "      <td>67</td>\n",
       "      <td>tvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.708628</td>\n",
       "      <td>0.714124</td>\n",
       "      <td>289</td>\n",
       "      <td>343</td>\n",
       "      <td>98</td>\n",
       "      <td>155</td>\n",
       "      <td>cvec, ngram_range = (1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.633988</td>\n",
       "      <td>0.659887</td>\n",
       "      <td>290</td>\n",
       "      <td>294</td>\n",
       "      <td>147</td>\n",
       "      <td>154</td>\n",
       "      <td>cvec, ngram_range = (1,2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  cv_score  test_score   tn   tp   fn   fp  \\\n",
       "0              nb  0.897099    0.906215  415  387   54   29   \n",
       "1             svm  0.895590    0.905085  401  400   41   43   \n",
       "2          logreg  0.891065    0.905085  401  400   41   43   \n",
       "3             svm  0.895964    0.902825  391  408   33   53   \n",
       "4          logreg  0.894836    0.901695  388  410   31   56   \n",
       "5              nb  0.898604    0.898305  402  393   48   42   \n",
       "6          logreg  0.869950    0.884746  371  412   29   73   \n",
       "7          logreg  0.869948    0.881356  369  411   30   75   \n",
       "8              nb  0.883908    0.877966  420  357   84   24   \n",
       "9       extratree  0.854885    0.875706  407  368   73   37   \n",
       "10   randomforest  0.854510    0.872316  410  362   79   34   \n",
       "11      extratree  0.840569    0.871186  409  362   79   35   \n",
       "12   randomforest  0.852244    0.871186  407  364   77   37   \n",
       "13             nb  0.879760    0.870056  416  354   87   28   \n",
       "14      extratree  0.848863    0.858757  401  359   82   43   \n",
       "15   randomforest  0.845462    0.851977  391  363   78   53   \n",
       "16      extratree  0.832652    0.847458  396  354   87   48   \n",
       "17   randomforest  0.835283    0.844068  401  346   95   43   \n",
       "18  gradientboost  0.837534    0.841808  333  412   29  111   \n",
       "19  gradientboost  0.840548    0.837288  329  412   29  115   \n",
       "20  gradientboost  0.832632    0.836158  333  407   34  111   \n",
       "21        bagging  0.805873    0.833898  383  355   86   61   \n",
       "22        bagging  0.814921    0.832768  380  357   84   64   \n",
       "23        bagging  0.807008    0.831638  389  347   94   55   \n",
       "24       adaboost  0.794183    0.830508  371  364   77   73   \n",
       "25            svm  0.813031    0.828249  336  397   44  108   \n",
       "26  gradientboost  0.836773    0.827119  322  410   31  122   \n",
       "27       adaboost  0.797582    0.818079  377  347   94   67   \n",
       "28        bagging  0.804749    0.816949  392  331  110   52   \n",
       "29       adaboost  0.795696    0.816949  372  351   90   72   \n",
       "30            svm  0.797201    0.815819  318  404   37  126   \n",
       "31       adaboost  0.793440    0.810169  377  340  101   67   \n",
       "32           cart  0.780615    0.796610  376  329  112   68   \n",
       "33           cart  0.779866    0.796610  370  335  106   74   \n",
       "34           cart  0.786267    0.792090  361  340  101   83   \n",
       "35            knn  0.786287    0.787571  398  299  142   46   \n",
       "36            knn  0.788551    0.784181  395  299  142   49   \n",
       "37           cart  0.780240    0.772881  377  307  134   67   \n",
       "38            knn  0.708628    0.714124  289  343   98  155   \n",
       "39            knn  0.633988    0.659887  290  294  147  154   \n",
       "\n",
       "                         vect  \n",
       "0   cvec, ngram_range = (1,2)  \n",
       "1   tvec, ngram_range = (1,2)  \n",
       "2   tvec, ngram_range = (1,2)  \n",
       "3   tvec, ngram_range = (1,1)  \n",
       "4   tvec, ngram_range = (1,1)  \n",
       "5   cvec, ngram_range = (1,1)  \n",
       "6   cvec, ngram_range = (1,2)  \n",
       "7   cvec, ngram_range = (1,1)  \n",
       "8   tvec, ngram_range = (1,2)  \n",
       "9   tvec, ngram_range = (1,1)  \n",
       "10  tvec, ngram_range = (1,1)  \n",
       "11  cvec, ngram_range = (1,1)  \n",
       "12  cvec, ngram_range = (1,1)  \n",
       "13  tvec, ngram_range = (1,1)  \n",
       "14  tvec, ngram_range = (1,2)  \n",
       "15  cvec, ngram_range = (1,2)  \n",
       "16  cvec, ngram_range = (1,2)  \n",
       "17  tvec, ngram_range = (1,2)  \n",
       "18  cvec, ngram_range = (1,2)  \n",
       "19  cvec, ngram_range = (1,1)  \n",
       "20  tvec, ngram_range = (1,2)  \n",
       "21  cvec, ngram_range = (1,1)  \n",
       "22  cvec, ngram_range = (1,2)  \n",
       "23  tvec, ngram_range = (1,1)  \n",
       "24  cvec, ngram_range = (1,1)  \n",
       "25  cvec, ngram_range = (1,1)  \n",
       "26  tvec, ngram_range = (1,1)  \n",
       "27  tvec, ngram_range = (1,1)  \n",
       "28  tvec, ngram_range = (1,2)  \n",
       "29  cvec, ngram_range = (1,2)  \n",
       "30  cvec, ngram_range = (1,2)  \n",
       "31  tvec, ngram_range = (1,2)  \n",
       "32  cvec, ngram_range = (1,2)  \n",
       "33  tvec, ngram_range = (1,1)  \n",
       "34  cvec, ngram_range = (1,1)  \n",
       "35  tvec, ngram_range = (1,2)  \n",
       "36  tvec, ngram_range = (1,1)  \n",
       "37  tvec, ngram_range = (1,2)  \n",
       "38  cvec, ngram_range = (1,1)  \n",
       "39  cvec, ngram_range = (1,2)  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-04, 7.74263683e-04, 5.99484250e-03, 4.64158883e-02,\n",
       "       3.59381366e-01, 2.78255940e+00, 2.15443469e+01, 1.66810054e+02,\n",
       "       1.29154967e+03, 1.00000000e+04])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-4,4,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "? TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipelines = [\n",
    "    {\n",
    "        'name': 'naive_bayes_cvec', \n",
    "        'vect': CountVectorizer(), \n",
    "        'model': MultinomialNB(), \n",
    "        'param_grid' : {\n",
    "                'vect__max_features': [None, 1000, 20000],\n",
    "                'vect__min_df': [1, 2, 5, 10],\n",
    "                'vect__max_df': [.5, .75,.9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)], \n",
    "                'naive_bayes_cvec__alpha': np.linspace(0.01, 1, 5)\n",
    "            }\n",
    "        \n",
    "    }, \n",
    "    {\n",
    "        'name': 'naive_bayes_tvec', \n",
    "        'vect': TfidfVectorizer(), \n",
    "        'model': MultinomialNB(), \n",
    "        'param_grid' : {\n",
    "                'vect__max_features': [None, 1000, 20000],\n",
    "                'vect__min_df': [1, 2, 5, 10],\n",
    "                'vect__max_df': [.5, .75,.9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)], \n",
    "                'naive_bayes_tvec__alpha': np.linspace(0.01, 1, 5)\n",
    "            }\n",
    "        \n",
    "    }, \n",
    "    {\n",
    "        'name': 'logistic_regression_cvec', \n",
    "        'vect': CountVectorizer(), \n",
    "        'ss' : StandardScaler(with_mean=False),\n",
    "        'model': LogisticRegression(max_iter=1000000), \n",
    "        'param_grid' : {\n",
    "                 'vect__max_features': [None, 1000, 20000],\n",
    "                'vect__min_df': [1, 2, 5, 10],\n",
    "                'vect__max_df': [.5, .75, .9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)],\n",
    "                'logistic_regression_cvec__C' : [0.0001, 0.01, 0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'logistic_regression_tvec', \n",
    "        'vect': TfidfVectorizer(), \n",
    "        'model': LogisticRegression(max_iter=1000000), \n",
    "        'param_grid' : {\n",
    "                'vect__max_features': [None, 1000, 20000],\n",
    "                'vect__min_df': [1, 2, 5, 10],\n",
    "                'vect__max_df': [.5, .75,.9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)],\n",
    "                'logistic_regression_tvec__C' : [0.0001, 0.01, 0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "     \n",
    "    {\n",
    "        'name': 'svm_cvec', \n",
    "        'vect': CountVectorizer(), \n",
    "        'model': SVC(), \n",
    "        'param_grid' : {\n",
    "                'vect__max_features': [None, 1000, 20000],\n",
    "                'vect__min_df': [1, 2, 5],\n",
    "                'vect__max_df': [.5, .8, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)],\n",
    "                'svm_cvec__C': [1.0, 10, 100], \n",
    "                'svm_cvec__gamma': ['auto', 'scale', 1, .1, .01],\n",
    "                'svm_cvec__kernel' : ['linear', 'rbf']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'svm_tvec', \n",
    "        'vect': TfidfVectorizer(), \n",
    "        'model': SVC(), \n",
    "        'param_grid' : {\n",
    "                'vect__max_features': [None, 1000, 20000],\n",
    "                'vect__min_df': [1, 2, 5],\n",
    "                'vect__max_df': [.5, .8, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)],\n",
    "                'svm_tvec__C': [1.0, 10, 100], \n",
    "                'svm_tvec__gamma': ['auto', 'scale', 1, .1, .01],\n",
    "                'svm_tvec__kernel' : ['linear', 'rbf']\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipelines = [\n",
    "{\n",
    "        'name': 'rf_cvec', \n",
    "        'vect': CountVectorizer(), \n",
    "        'model': RandomForestClassifier(), \n",
    "        'param_grid' : {\n",
    "                #'vect__max_features': [None, 1000, 20000],\n",
    "                #'vect__min_df': [1, 2, 5],\n",
    "                'vect__max_df': [.5,  1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)],\n",
    "                'rf_cvec__n_estimators': [100, 200],\n",
    "                'rf_cvec__max_depth': [None, 2, 4, 6, 8]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'rf_tvec', \n",
    "        'vect': TfidfVectorizer(), \n",
    "        'model': RandomForestClassifier(), \n",
    "        'param_grid' : {\n",
    "               #'vect__max_features': [None, 1000, 20000],\n",
    "                #'vect__min_df': [1, 2, 5],\n",
    "                'vect__max_df': [.5,  1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)],\n",
    "                'rf_tvec__n_estimators': [100, 200],\n",
    "                'rf_tvec__max_depth': [None, 2, 4, 6, 8]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'rf_cvec__max_depth': None, 'rf_cvec__n_estimators': 200, 'vect__max_df': 1.0, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8545023629321677\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 367\n",
      "True Negatives: 405\n",
      "False Positives: 39\n",
      "False Negatives: 74\n",
      "\n",
      "\n",
      "Accuracy: 0.8723163841807909\n",
      "Sensitivity/Recall (TPR): 0.8321995464852607\n",
      "Specificity (TNR): 0.9121621621621622\n",
      "Precision: 0.9039408866995073\n",
      "F1 Score: 0.8665879574970484\n",
      "\n",
      "======================\n",
      "\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'rf_tvec__max_depth': None, 'rf_tvec__n_estimators': 100, 'vect__max_df': 1.0, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8582787904629926\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 361\n",
      "True Negatives: 411\n",
      "False Positives: 33\n",
      "False Negatives: 80\n",
      "\n",
      "\n",
      "Accuracy: 0.8723163841807909\n",
      "Sensitivity/Recall (TPR): 0.81859410430839\n",
      "Specificity (TNR): 0.9256756756756757\n",
      "Precision: 0.916243654822335\n",
      "F1 Score: 0.8646706586826347\n",
      "\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_search_scores = pipe_gridsearch(rf_pipelines, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'rf_cvec__max_depth': None, 'rf_cvec__n_estimators': 200, 'vect__max_df': 1.0, 'vect__ngram_range': (1, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tvec_pipe = Pipeline([('tvec', TfidfVectorizer(max_df=0.5,max_features = None, min_df = 1, ngram_range=(1,2))), \n",
    "                         ('svm', SVC(C = 10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_cvec_pipe = Pipeline([('cvec', CountVectorizer()), ('rf', RandomForestClassifier(n_estimators = 200))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_tvec_pipe = Pipeline([('tvec', TfidfVectorizer()), ('rf', RandomForestClassifier(n_estimators = 100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cvec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=200, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest_cvec_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1329\n",
       "1    1324\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996230682246513"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest_cvec_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8511111111111112"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(randomforest_cvec_pipe, X_train, y_train, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8621468926553673"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest_cvec_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8264939259883435"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest_cvec_pipe.score(X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8473460540809438"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(randomforest_tvec_pipe, X_train, y_train, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tvec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest_tvec_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996230682246513"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest_tvec_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8598870056497175"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest_tvec_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 347\n",
      "True Negatives: 414\n",
      "False Positives: 29\n",
      "False Negatives: 95\n",
      "\n",
      "\n",
      "Accuracy: 0.8598870056497175\n",
      "Sensitivity/Recall (TPR): 0.7850678733031674\n",
      "Specificity (TNR): 0.9345372460496614\n",
      "Precision: 0.9228723404255319\n",
      "F1 Score: 0.8484107579462102\n",
      "\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = randomforest_tvec_pipe.predict(X_test)\n",
    "print(' ')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_hat).ravel()\n",
    "print('******** Test/Validation Scores ********')\n",
    "print(f'True Positives: {tp}')\n",
    "print(f'True Negatives: {tn}')\n",
    "print(f'False Positives: {fp}')\n",
    "print(f'False Negatives: {fn}')\n",
    "print('')\n",
    "print('')\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp+fn)\n",
    "print(f'Accuracy: {randomforest_tvec_pipe.score(X_test, y_test)}')\n",
    "print(f'Sensitivity/Recall (TPR): {recall}')\n",
    "print(f'Specificity (TNR): {tn/(tn+fp)}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'F1 Score: {2*(precision*recall)/(precision+recall)}')\n",
    "print('')      \n",
    "print('======================')\n",
    "print('')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 358\n",
      "True Negatives: 405\n",
      "False Positives: 38\n",
      "False Negatives: 84\n",
      "\n",
      "\n",
      "Accuracy: 0.8621468926553673\n",
      "Sensitivity/Recall (TPR): 0.8099547511312217\n",
      "Specificity (TNR): 0.9142212189616253\n",
      "Precision: 0.9040404040404041\n",
      "F1 Score: 0.8544152744630071\n",
      "\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = randomforest_cvec_pipe.predict(X_test)\n",
    "print(' ')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_hat).ravel()\n",
    "print('******** Test/Validation Scores ********')\n",
    "print(f'True Positives: {tp}')\n",
    "print(f'True Negatives: {tn}')\n",
    "print(f'False Positives: {fp}')\n",
    "print(f'False Negatives: {fn}')\n",
    "print('')\n",
    "print('')\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp+fn)\n",
    "print(f'Accuracy: {randomforest_cvec_pipe.score(X_test, y_test)}')\n",
    "print(f'Sensitivity/Recall (TPR): {recall}')\n",
    "print(f'Specificity (TNR): {tn/(tn+fp)}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'F1 Score: {2*(precision*recall)/(precision+recall)}')\n",
    "print('')      \n",
    "print('======================')\n",
    "print('')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2652,)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_dupdrop_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_gridsearch(pipelines, X_train, y_train, X_val, y_val):\n",
    "    scores = []\n",
    "    for pipe_data in pipelines: \n",
    "        if 'ss' in pipe_data.keys():\n",
    "            pipe = Pipeline([\n",
    "                ('vect', pipe_data['vect']),\n",
    "                ('ss', pipe_data['ss']),\n",
    "                (pipe_data['name'], pipe_data['model'])\n",
    "                ])\n",
    "        else:\n",
    "            pipe = Pipeline([\n",
    "                    ('vect', pipe_data['vect']),\n",
    "                    (pipe_data['name'], pipe_data['model'])\n",
    "                    ])\n",
    "        \n",
    "        \n",
    "        gs = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                          param_grid=pipe_data['param_grid'], # what parameters values are we searching?\n",
    "                          cv=5, n_jobs=4, verbose = 1) # 5-fold cross-validation.\n",
    "        \n",
    "       \n",
    "    \n",
    "        gs.fit(X_train, y_train)\n",
    "        score = gs.best_score_\n",
    "\n",
    "        print('======== Score Report =======')\n",
    "        print('')\n",
    "        print(f'Model: {type(pipe_data[\"model\"])}')\n",
    "        print(f'Vectorizer: {pipe_data[\"vect\"]}')\n",
    "        print('')\n",
    "        print('')\n",
    "        print(f'Best Parameters: {gs.best_params_}')\n",
    "\n",
    "        print('')\n",
    "        print('******** Cross-Validation Scores ********')\n",
    "        print(f'Mean 5-fold CV accuracy: {gs.best_score_}')\n",
    "      \n",
    "\n",
    "        y_hat = gs.predict(X_val)\n",
    "        print(' ')\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_hat).ravel()\n",
    "        print('******** Test/Validation Scores ********')\n",
    "        print(f'True Positives: {tp}')\n",
    "        print(f'True Negatives: {tn}')\n",
    "        print(f'False Positives: {fp}')\n",
    "        print(f'False Negatives: {fn}')\n",
    "        print('')\n",
    "        print('')\n",
    "        precision = tp/(tp + fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        print(f'Accuracy: {gs.score(X_val, y_val)}')\n",
    "        print(f'Sensitivity/Recall (TPR): {recall}')\n",
    "        print(f'Specificity (TNR): {tn/(tn+fp)}')\n",
    "        print(f'Precision: {precision}')\n",
    "        print(f'F1 Score: {2*(precision*recall)/(precision+recall)}')\n",
    "        print('')      \n",
    "        print('======================')\n",
    "        print('')      \n",
    "        \n",
    "        curr_score = {}\n",
    "        curr_score['name'] = pipe_data['name']\n",
    "        curr_score['best_params'] = gs.best_params_\n",
    "        curr_score['cv_score'] = gs.best_score_\n",
    "        curr_score['val_score'] = gs.score(X_val, y_val)\n",
    "        curr_score['tp'] = tp\n",
    "        curr_score['tn'] = tn\n",
    "        curr_score['fp'] = fp\n",
    "        curr_score['fn'] = fn\n",
    "        scores.append(curr_score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2653,)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=4)]: Done 2400 out of 2400 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'naive_bayes_cvec__alpha': 1.0, 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__min_df': 1, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8989837615037487\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 393\n",
      "True Negatives: 402\n",
      "False Positives: 42\n",
      "False Negatives: 48\n",
      "\n",
      "\n",
      "Accuracy: 0.8983050847457628\n",
      "Sensitivity/Recall (TPR): 0.891156462585034\n",
      "Specificity (TNR): 0.9054054054054054\n",
      "Precision: 0.903448275862069\n",
      "F1 Score: 0.8972602739726028\n",
      "\n",
      "======================\n",
      "\n",
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   49.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=4)]: Done 2400 out of 2400 | elapsed:  9.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'naive_bayes_tvec__alpha': 0.7525, 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8857925594286323\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 376\n",
      "True Negatives: 412\n",
      "False Positives: 32\n",
      "False Negatives: 65\n",
      "\n",
      "\n",
      "Accuracy: 0.8903954802259887\n",
      "Sensitivity/Recall (TPR): 0.8526077097505669\n",
      "Specificity (TNR): 0.9279279279279279\n",
      "Precision: 0.9215686274509803\n",
      "F1 Score: 0.8857479387514722\n",
      "\n",
      "======================\n",
      "\n",
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=4)]: Done 2400 out of 2400 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'logistic_regression_cvec__C': 0.01, 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8413125821696337\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 397\n",
      "True Negatives: 352\n",
      "False Positives: 92\n",
      "False Negatives: 44\n",
      "\n",
      "\n",
      "Accuracy: 0.8463276836158192\n",
      "Sensitivity/Recall (TPR): 0.9002267573696145\n",
      "Specificity (TNR): 0.7927927927927928\n",
      "Precision: 0.8118609406952966\n",
      "F1 Score: 0.853763440860215\n",
      "\n",
      "======================\n",
      "\n",
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done 2400 out of 2400 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'logistic_regression_tvec__C': 1, 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__min_df': 1, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8959641829229292\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 410\n",
      "True Negatives: 388\n",
      "False Positives: 56\n",
      "False Negatives: 31\n",
      "\n",
      "\n",
      "Accuracy: 0.9016949152542373\n",
      "Sensitivity/Recall (TPR): 0.9297052154195011\n",
      "Specificity (TNR): 0.8738738738738738\n",
      "Precision: 0.8798283261802575\n",
      "F1 Score: 0.9040793825799338\n",
      "\n",
      "======================\n",
      "\n",
      "Fitting 5 folds for each of 1620 candidates, totalling 8100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed: 43.5min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed: 51.6min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed: 64.0min\n",
      "[Parallel(n_jobs=4)]: Done 8100 out of 8100 | elapsed: 72.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.svm._classes.SVC'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'svm_cvec__C': 10, 'svm_cvec__gamma': 'scale', 'svm_cvec__kernel': 'rbf', 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__min_df': 1, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8575105710123297\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 403\n",
      "True Negatives: 365\n",
      "False Positives: 79\n",
      "False Negatives: 38\n",
      "\n",
      "\n",
      "Accuracy: 0.8677966101694915\n",
      "Sensitivity/Recall (TPR): 0.9138321995464853\n",
      "Specificity (TNR): 0.8220720720720721\n",
      "Precision: 0.8360995850622407\n",
      "F1 Score: 0.8732394366197183\n",
      "\n",
      "======================\n",
      "\n",
      "Fitting 5 folds for each of 1620 candidates, totalling 8100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed: 33.5min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed: 42.3min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed: 51.6min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed: 74.4min\n",
      "[Parallel(n_jobs=4)]: Done 8100 out of 8100 | elapsed: 82.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.svm._classes.SVC'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'svm_tvec__C': 10, 'svm_tvec__gamma': 'scale', 'svm_tvec__kernel': 'rbf', 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__min_df': 1, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8997327932345522\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 403\n",
      "True Negatives: 401\n",
      "False Positives: 43\n",
      "False Negatives: 38\n",
      "\n",
      "\n",
      "Accuracy: 0.9084745762711864\n",
      "Sensitivity/Recall (TPR): 0.9138321995464853\n",
      "Specificity (TNR): 0.9031531531531531\n",
      "Precision: 0.9035874439461884\n",
      "F1 Score: 0.9086809470124013\n",
      "\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_scores = pipe_gridsearch(pipelines, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4423,)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.concat([X_train, y_train], axis = 1), pd.concat([X_val,y_val], axis = 1), pd.concat([X_val, y_val], axis = 1)], axis = 0).to_csv('./mathphysics_trainvaltest.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2217\n",
       "1    2206\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_X  = pd.concat([pd.concat([X_train, y_train], axis = 1), pd.concat([X_val,y_val], axis = 1), pd.concat([X_val, y_val], axis = 1)], axis = 0)\n",
    "real_X['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.to_csv('./X_train.csv', index = False)\n",
    "#X_val.to_csv('./X_val.csv', index = False)\n",
    "#X_test.to_csv('./X_test.csv', index = False)\n",
    "#y_train.to_csv('./y_train.csv', index = False)\n",
    "#y_val.to_csv('./y_val.csv', index = False)\n",
    "#y_test.to_csv('./y_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49875650011304545"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2206/4423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.500942\n",
       "1    0.499058\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>best_params</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm_tvec</td>\n",
       "      <td>{'svm_tvec__C': 10, 'svm_tvec__gamma': 'scale'...</td>\n",
       "      <td>0.899733</td>\n",
       "      <td>0.908475</td>\n",
       "      <td>403</td>\n",
       "      <td>401</td>\n",
       "      <td>43</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic_regression_tvec</td>\n",
       "      <td>{'logistic_regression_tvec__C': 1, 'vect__max_...</td>\n",
       "      <td>0.895964</td>\n",
       "      <td>0.901695</td>\n",
       "      <td>410</td>\n",
       "      <td>388</td>\n",
       "      <td>56</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive_bayes_cvec</td>\n",
       "      <td>{'naive_bayes_cvec__alpha': 1.0, 'vect__max_df...</td>\n",
       "      <td>0.898984</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>393</td>\n",
       "      <td>402</td>\n",
       "      <td>42</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive_bayes_tvec</td>\n",
       "      <td>{'naive_bayes_tvec__alpha': 0.7525, 'vect__max...</td>\n",
       "      <td>0.885793</td>\n",
       "      <td>0.890395</td>\n",
       "      <td>376</td>\n",
       "      <td>412</td>\n",
       "      <td>32</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm_cvec</td>\n",
       "      <td>{'svm_cvec__C': 10, 'svm_cvec__gamma': 'scale'...</td>\n",
       "      <td>0.857511</td>\n",
       "      <td>0.867797</td>\n",
       "      <td>403</td>\n",
       "      <td>365</td>\n",
       "      <td>79</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression_cvec</td>\n",
       "      <td>{'logistic_regression_cvec__C': 0.01, 'vect__m...</td>\n",
       "      <td>0.841313</td>\n",
       "      <td>0.846328</td>\n",
       "      <td>397</td>\n",
       "      <td>352</td>\n",
       "      <td>92</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  \\\n",
       "5                  svm_tvec   \n",
       "3  logistic_regression_tvec   \n",
       "0          naive_bayes_cvec   \n",
       "1          naive_bayes_tvec   \n",
       "4                  svm_cvec   \n",
       "2  logistic_regression_cvec   \n",
       "\n",
       "                                         best_params  cv_score  val_score  \\\n",
       "5  {'svm_tvec__C': 10, 'svm_tvec__gamma': 'scale'...  0.899733   0.908475   \n",
       "3  {'logistic_regression_tvec__C': 1, 'vect__max_...  0.895964   0.901695   \n",
       "0  {'naive_bayes_cvec__alpha': 1.0, 'vect__max_df...  0.898984   0.898305   \n",
       "1  {'naive_bayes_tvec__alpha': 0.7525, 'vect__max...  0.885793   0.890395   \n",
       "4  {'svm_cvec__C': 10, 'svm_cvec__gamma': 'scale'...  0.857511   0.867797   \n",
       "2  {'logistic_regression_cvec__C': 0.01, 'vect__m...  0.841313   0.846328   \n",
       "\n",
       "    tp   tn  fp  fn  \n",
       "5  403  401  43  38  \n",
       "3  410  388  56  31  \n",
       "0  393  402  42  48  \n",
       "1  376  412  32  65  \n",
       "4  403  365  79  38  \n",
       "2  397  352  92  44  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(search_scores).sort_values('val_score', ascending = False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./mathphysicsresults.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>best_params</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_tvec</td>\n",
       "      <td>{'svm_tvec__C': 10, 'svm_tvec__gamma': 'scale'...</td>\n",
       "      <td>0.899733</td>\n",
       "      <td>0.908475</td>\n",
       "      <td>403</td>\n",
       "      <td>401</td>\n",
       "      <td>43</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_regression_tvec</td>\n",
       "      <td>{'logistic_regression_tvec__C': 1, 'vect__max_...</td>\n",
       "      <td>0.895964</td>\n",
       "      <td>0.901695</td>\n",
       "      <td>410</td>\n",
       "      <td>388</td>\n",
       "      <td>56</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive_bayes_cvec</td>\n",
       "      <td>{'naive_bayes_cvec__alpha': 1.0, 'vect__max_df...</td>\n",
       "      <td>0.898984</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>393</td>\n",
       "      <td>402</td>\n",
       "      <td>42</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naive_bayes_tvec</td>\n",
       "      <td>{'naive_bayes_tvec__alpha': 0.7525, 'vect__max...</td>\n",
       "      <td>0.885793</td>\n",
       "      <td>0.890395</td>\n",
       "      <td>376</td>\n",
       "      <td>412</td>\n",
       "      <td>32</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm_cvec</td>\n",
       "      <td>{'svm_cvec__C': 10, 'svm_cvec__gamma': 'scale'...</td>\n",
       "      <td>0.857511</td>\n",
       "      <td>0.867797</td>\n",
       "      <td>403</td>\n",
       "      <td>365</td>\n",
       "      <td>79</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logistic_regression_cvec</td>\n",
       "      <td>{'logistic_regression_cvec__C': 0.01, 'vect__m...</td>\n",
       "      <td>0.841313</td>\n",
       "      <td>0.846328</td>\n",
       "      <td>397</td>\n",
       "      <td>352</td>\n",
       "      <td>92</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  \\\n",
       "0                  svm_tvec   \n",
       "1  logistic_regression_tvec   \n",
       "2          naive_bayes_cvec   \n",
       "3          naive_bayes_tvec   \n",
       "4                  svm_cvec   \n",
       "5  logistic_regression_cvec   \n",
       "\n",
       "                                         best_params  cv_score  val_score  \\\n",
       "0  {'svm_tvec__C': 10, 'svm_tvec__gamma': 'scale'...  0.899733   0.908475   \n",
       "1  {'logistic_regression_tvec__C': 1, 'vect__max_...  0.895964   0.901695   \n",
       "2  {'naive_bayes_cvec__alpha': 1.0, 'vect__max_df...  0.898984   0.898305   \n",
       "3  {'naive_bayes_tvec__alpha': 0.7525, 'vect__max...  0.885793   0.890395   \n",
       "4  {'svm_cvec__C': 10, 'svm_cvec__gamma': 'scale'...  0.857511   0.867797   \n",
       "5  {'logistic_regression_cvec__C': 0.01, 'vect__m...  0.841313   0.846328   \n",
       "\n",
       "    tp   tn  fp  fn  \n",
       "0  403  401  43  38  \n",
       "1  410  388  56  31  \n",
       "2  393  402  42  48  \n",
       "3  376  412  32  65  \n",
       "4  403  365  79  38  \n",
       "5  397  352  92  44  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svm_tvec__C': 10,\n",
       " 'svm_tvec__gamma': 'scale',\n",
       " 'svm_tvec__kernel': 'rbf',\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[0]['best_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tvec_pipe = Pipeline([('tvec', TfidfVectorizer(max_df=0.5,max_features = None, min_df = 1, ngram_range=(1,2))), \n",
    "                         ('svm', SVC(C = 10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tvec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.5, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('svm',\n",
       "                 SVC(C=10, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_tvec_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996230682246513"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_tvec_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9084745762711864"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_tvec_pipe.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8997327932345522"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svm_tvec_pipe, X_train, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9028248587570622"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_tvec_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8724387332350256"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_tvec_pipe.score(X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 392\n",
      "True Negatives: 407\n",
      "False Positives: 36\n",
      "False Negatives: 50\n",
      "\n",
      "\n",
      "Accuracy: 0.9028248587570622\n",
      "Sensitivity/Recall (TPR): 0.8868778280542986\n",
      "Specificity (TNR): 0.9187358916478555\n",
      "Precision: 0.9158878504672897\n",
      "F1 Score: 0.9011494252873563\n",
      "\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = svm_tvec_pipe.predict(X_test)\n",
    "print(' ')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_hat).ravel()\n",
    "print('******** Test/Validation Scores ********')\n",
    "print(f'True Positives: {tp}')\n",
    "print(f'True Negatives: {tn}')\n",
    "print(f'False Positives: {fp}')\n",
    "print(f'False Negatives: {fn}')\n",
    "print('')\n",
    "print('')\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp+fn)\n",
    "print(f'Accuracy: {svm_tvec_pipe.score(X_test, y_test)}')\n",
    "print(f'Sensitivity/Recall (TPR): {recall}')\n",
    "print(f'Specificity (TNR): {tn/(tn+fp)}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'F1 Score: {2*(precision*recall)/(precision+recall)}')\n",
    "print('')      \n",
    "print('======================')\n",
    "print('')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic_regression_tvec__C': 1,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[1]['best_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_tvec_pipe = Pipeline([('tvec', TfidfVectorizer(max_df=0.5,max_features = None, min_df = 1, ngram_range=(1,1))), \n",
    "                         ('logreg', LogisticRegression(C = 1))])\n",
    "logreg_tvec_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8959641829229292"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logreg_tvec_pipe, X_train, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973237843950245"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_tvec_pipe.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9016949152542373"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_tvec_pipe.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9050847457627119"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_tvec_pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_logreg = logreg_tvec_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 399\n",
      "True Negatives: 402\n",
      "False Positives: 41\n",
      "False Negatives: 43\n",
      "\n",
      "\n",
      "Accuracy: 0.9050847457627119\n",
      "Sensitivity/Recall (TPR): 0.9027149321266968\n",
      "Specificity (TNR): 0.90744920993228\n",
      "Precision: 0.9068181818181819\n",
      "F1 Score: 0.9047619047619048\n",
      "\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = logreg_tvec_pipe.predict(X_test)\n",
    "print(' ')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_hat).ravel()\n",
    "print('******** Test/Validation Scores ********')\n",
    "print(f'True Positives: {tp}')\n",
    "print(f'True Negatives: {tn}')\n",
    "print(f'False Positives: {fp}')\n",
    "print(f'False Negatives: {fn}')\n",
    "print('')\n",
    "print('')\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp+fn)\n",
    "print(f'Accuracy: {logreg_tvec_pipe.score(X_test, y_test)}')\n",
    "print(f'Sensitivity/Recall (TPR): {recall}')\n",
    "print(f'Specificity (TNR): {tn/(tn+fp)}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'F1 Score: {2*(precision*recall)/(precision+recall)}')\n",
    "print('')      \n",
    "print('======================')\n",
    "print('')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2521673577082548"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[402,  41],\n",
       "       [ 43, 399]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8681272382557405"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_tvec_pipe.score(X_all,y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141825,)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.516023\n",
       "1    0.483977\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1043523 , -0.01822773, -0.00558622, ...,  0.03166715,\n",
       "       -0.11973274, -0.25350284])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_tvec_pipe.named_steps['logreg'].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__',\n",
       " '_axb',\n",
       " '_b',\n",
       " '_crazy_',\n",
       " '_e',\n",
       " '_easier_',\n",
       " '_f',\n",
       " '_i',\n",
       " '_ij',\n",
       " '_infinity',\n",
       " '_j',\n",
       " '_kinda_',\n",
       " '_l',\n",
       " '_more_',\n",
       " '_n',\n",
       " '_nx',\n",
       " '_o',\n",
       " '_problem',\n",
       " '_really_',\n",
       " '_t',\n",
       " '_tt',\n",
       " '_tuned_',\n",
       " '_tx',\n",
       " '_user',\n",
       " '_usually_',\n",
       " '_v',\n",
       " '_why_',\n",
       " '_x',\n",
       " '_xn',\n",
       " '_xx',\n",
       " 'a_i',\n",
       " 'a_n',\n",
       " 'aalto',\n",
       " 'aang',\n",
       " 'ab',\n",
       " 'abacus',\n",
       " 'abaff',\n",
       " 'abandoned',\n",
       " 'abbott',\n",
       " 'abc',\n",
       " 'abdul',\n",
       " 'abelian',\n",
       " 'abelson',\n",
       " 'aberrated',\n",
       " 'aberration',\n",
       " 'abhijeet',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abnormal',\n",
       " 'abroad',\n",
       " 'absement',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorption',\n",
       " 'abstract',\n",
       " 'abstracted',\n",
       " 'abstraction',\n",
       " 'abstractly',\n",
       " 'absurd',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abv',\n",
       " 'ac',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academically',\n",
       " 'academie',\n",
       " 'academy',\n",
       " 'acapella',\n",
       " 'acca',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerating',\n",
       " 'acceleration',\n",
       " 'accelerator',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accommodate',\n",
       " 'accompanied',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishment',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accountancy',\n",
       " 'accountant',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accreditation',\n",
       " 'accredited',\n",
       " 'accreting',\n",
       " 'accumulate',\n",
       " 'accumulation',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusing',\n",
       " 'ace',\n",
       " 'aced',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achieving',\n",
       " 'acl',\n",
       " 'acm',\n",
       " 'acmtechtalk',\n",
       " 'acorn',\n",
       " 'acoustic',\n",
       " 'acoustical',\n",
       " 'acquaintance',\n",
       " 'acquire',\n",
       " 'acquiring',\n",
       " 'acronym',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'actio',\n",
       " 'action',\n",
       " 'activated',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activity',\n",
       " 'actual',\n",
       " 'actualize',\n",
       " 'actually',\n",
       " 'actualy',\n",
       " 'actuarial',\n",
       " 'actuary',\n",
       " 'actuaryuk',\n",
       " 'actuator',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additive',\n",
       " 'addittion',\n",
       " 'address',\n",
       " 'addressing',\n",
       " 'addvice',\n",
       " 'adeliade',\n",
       " 'adequate',\n",
       " 'adhd',\n",
       " 'adhesive',\n",
       " 'adiabatic',\n",
       " 'adjacent',\n",
       " 'adjoint',\n",
       " 'adjunct',\n",
       " 'adjust',\n",
       " 'adjustment',\n",
       " 'administered',\n",
       " 'administration',\n",
       " 'admins',\n",
       " 'admire',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'ado',\n",
       " 'adolf',\n",
       " 'adoration',\n",
       " 'adored',\n",
       " 'adrenaline',\n",
       " 'adt',\n",
       " 'adult',\n",
       " 'advait',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advantage',\n",
       " 'advent',\n",
       " 'adventure',\n",
       " 'adverse',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'adviser',\n",
       " 'advises',\n",
       " 'advisor',\n",
       " 'advocated',\n",
       " 'aero',\n",
       " 'aerodynamics',\n",
       " 'aesthetic',\n",
       " 'af',\n",
       " 'afaik',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affiliated',\n",
       " 'affine',\n",
       " 'affirm',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'aficionado',\n",
       " 'afloat',\n",
       " 'aforementioned',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africanism',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'afterwords',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agenda',\n",
       " 'aggregate',\n",
       " 'aggregation',\n",
       " 'aging',\n",
       " 'aglow',\n",
       " 'agnesi',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahmed',\n",
       " 'ai',\n",
       " 'aib',\n",
       " 'aid',\n",
       " 'aida',\n",
       " 'aim',\n",
       " 'aime',\n",
       " 'aimed',\n",
       " 'aimlessly',\n",
       " 'air',\n",
       " 'airborne',\n",
       " 'aircraft',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airspeed',\n",
       " 'airstrip',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alaska',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alchemy',\n",
       " 'alcohol',\n",
       " 'alejandra',\n",
       " 'aleks',\n",
       " 'alembert',\n",
       " 'alemberts',\n",
       " 'aleph',\n",
       " 'alert',\n",
       " 'alessandro',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandre',\n",
       " 'alexandrov',\n",
       " 'alfred',\n",
       " 'alg',\n",
       " 'algebra',\n",
       " 'algebraic',\n",
       " 'algebraically',\n",
       " 'algol',\n",
       " 'algorithm',\n",
       " 'algorithmic',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'allen',\n",
       " 'allergy',\n",
       " 'alley',\n",
       " 'allocation',\n",
       " 'allow',\n",
       " 'allowable',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allready',\n",
       " 'alma',\n",
       " 'almost',\n",
       " 'aln',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'alpha',\n",
       " 'alphabetical',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'alrighty',\n",
       " 'also',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alters',\n",
       " 'although',\n",
       " 'altitude',\n",
       " 'altogether',\n",
       " 'aluminium',\n",
       " 'alvarado',\n",
       " 'always',\n",
       " 'am',\n",
       " 'ama',\n",
       " 'amateur',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'ambient',\n",
       " 'ambiguous',\n",
       " 'ambition',\n",
       " 'ambitious',\n",
       " 'amc',\n",
       " 'amcs',\n",
       " 'amd',\n",
       " 'amend',\n",
       " 'america',\n",
       " 'american',\n",
       " 'amiss',\n",
       " 'ammount',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'ampere',\n",
       " 'ampersand',\n",
       " 'ample',\n",
       " 'amplitude',\n",
       " 'amusing',\n",
       " 'an',\n",
       " 'analogous',\n",
       " 'analogue',\n",
       " 'analogy',\n",
       " 'analysed',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analytic',\n",
       " 'analytical',\n",
       " 'analytically',\n",
       " 'analytics',\n",
       " 'analyze',\n",
       " 'analyzed',\n",
       " 'analyzer',\n",
       " 'analyzing',\n",
       " 'anatomy',\n",
       " 'anchor',\n",
       " 'anchored',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'anddddd',\n",
       " 'andrea',\n",
       " 'andrei',\n",
       " 'andriy',\n",
       " 'android',\n",
       " 'andromeda',\n",
       " 'anecdotally',\n",
       " 'angel',\n",
       " 'anger',\n",
       " 'angie',\n",
       " 'angle',\n",
       " 'angry',\n",
       " 'angular',\n",
       " 'angularly',\n",
       " 'animal',\n",
       " 'animate',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'anime',\n",
       " 'anki',\n",
       " 'anna',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'annoy',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoys',\n",
       " 'annual',\n",
       " 'anomalous',\n",
       " 'anomaly',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'answears',\n",
       " 'answer',\n",
       " 'answerable',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'ant',\n",
       " 'antarctica',\n",
       " 'antecedent',\n",
       " 'anthony',\n",
       " 'anthropological',\n",
       " 'anthropology',\n",
       " 'anti',\n",
       " 'anticategory',\n",
       " 'anticipating',\n",
       " 'anticipation',\n",
       " 'anticlockwise',\n",
       " 'antiderivative',\n",
       " 'antiderivatives',\n",
       " 'antielectron',\n",
       " 'antiferromagnet',\n",
       " 'antimatter',\n",
       " 'antimony',\n",
       " 'antineutrino',\n",
       " 'antinoise',\n",
       " 'antiparticle',\n",
       " 'anton',\n",
       " 'antoni',\n",
       " 'antonidakis',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyones',\n",
       " 'anyplace',\n",
       " 'anything',\n",
       " 'anythinig',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'aome',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apathy',\n",
       " 'aperture',\n",
       " 'apery',\n",
       " 'apex',\n",
       " 'apexi',\n",
       " 'aplication',\n",
       " 'apologise',\n",
       " 'apologize',\n",
       " 'apologized',\n",
       " 'apology',\n",
       " 'apostol',\n",
       " 'app',\n",
       " 'apparatus',\n",
       " 'apparel',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealed',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appeard',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'apple',\n",
       " 'applicable',\n",
       " 'applicant',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciation',\n",
       " 'apprehensive',\n",
       " 'apprenticeship',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approx',\n",
       " 'approximate',\n",
       " 'approximately',\n",
       " 'approximating',\n",
       " 'approximation',\n",
       " 'apps',\n",
       " 'aprrox',\n",
       " 'aps',\n",
       " 'aptitude',\n",
       " 'aptly',\n",
       " 'aq',\n",
       " 'ar',\n",
       " 'arabic',\n",
       " 'arb',\n",
       " 'arbirtrary',\n",
       " 'arbitrarily',\n",
       " 'arbitrary',\n",
       " 'arbitraty',\n",
       " 'arc',\n",
       " 'archimedes',\n",
       " 'architectural',\n",
       " 'archive',\n",
       " 'arclength',\n",
       " 'arcsin',\n",
       " 'arctan',\n",
       " 'area',\n",
       " 'arena',\n",
       " 'areospace',\n",
       " 'arfken',\n",
       " 'argand',\n",
       " 'arguably',\n",
       " 'argue',\n",
       " 'argued',\n",
       " 'argues',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'arise',\n",
       " 'arises',\n",
       " 'aristotelian',\n",
       " 'arithmetic',\n",
       " 'arkani',\n",
       " 'arlie',\n",
       " 'arm',\n",
       " 'armor',\n",
       " 'army',\n",
       " 'arnold',\n",
       " 'arose',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arranged',\n",
       " 'arrangement',\n",
       " 'arranging',\n",
       " 'array',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'arrow',\n",
       " 'arrt',\n",
       " 'art',\n",
       " 'artefact',\n",
       " 'arthur',\n",
       " 'article',\n",
       " 'articulate',\n",
       " 'articulation',\n",
       " 'artificial',\n",
       " 'artificially',\n",
       " 'artin',\n",
       " 'artist',\n",
       " 'artistically',\n",
       " 'arxiv',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ascending',\n",
       " 'ascribed',\n",
       " 'ashamed',\n",
       " 'asia',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'ask_a_scientist_gaming',\n",
       " 'askacademia',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'askmath',\n",
       " 'askphysics',\n",
       " 'asks',\n",
       " 'askscience',\n",
       " 'asleep',\n",
       " 'aslo',\n",
       " 'aspect',\n",
       " 'aspired',\n",
       " 'aspiring',\n",
       " 'ass',\n",
       " 'assamise',\n",
       " 'assemble',\n",
       " 'assembled',\n",
       " 'assembly',\n",
       " 'asserting',\n",
       " 'assertion',\n",
       " 'asserts',\n",
       " 'assessing',\n",
       " 'assessment',\n",
       " 'assign',\n",
       " 'assigned',\n",
       " 'assigning',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'assisting',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'associative',\n",
       " 'associativity',\n",
       " 'assortment',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assumes',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assure',\n",
       " 'asterisk',\n",
       " 'asteroid',\n",
       " 'astonishing',\n",
       " 'astro',\n",
       " 'astrology',\n",
       " 'astronomer',\n",
       " 'astronomical',\n",
       " 'astronomy',\n",
       " 'astroparticle',\n",
       " 'astrophysicist',\n",
       " 'astrophysics',\n",
       " 'aswell',\n",
       " 'asymmetric',\n",
       " 'asymmetry',\n",
       " 'asymptote',\n",
       " 'asymptotic',\n",
       " 'asymptotics',\n",
       " 'asymtope',\n",
       " 'asynchronous',\n",
       " 'atan',\n",
       " 'atari',\n",
       " 'ate',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atom',\n",
       " 'atomic',\n",
       " 'atomical',\n",
       " 'atop',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attain',\n",
       " 'attained',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attend',\n",
       " 'attended',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'attract',\n",
       " 'attracted',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attribute',\n",
       " 'attributed',\n",
       " 'atypical',\n",
       " 'auction',\n",
       " 'audience',\n",
       " 'audio',\n",
       " 'audit',\n",
       " 'aug',\n",
       " 'august',\n",
       " 'auiod',\n",
       " 'austere',\n",
       " 'australia',\n",
       " 'author',\n",
       " 'authored',\n",
       " 'authority',\n",
       " 'autistic',\n",
       " 'auto',\n",
       " 'automas',\n",
       " 'automate',\n",
       " 'automated',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'automating',\n",
       " 'automaton',\n",
       " 'automorphic',\n",
       " 'automotive',\n",
       " 'autonomy',\n",
       " 'autumn',\n",
       " 'avagadro',\n",
       " 'avail',\n",
       " 'available',\n",
       " 'avatar',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'averaging',\n",
       " 'averse',\n",
       " 'avi',\n",
       " 'avian',\n",
       " 'avid',\n",
       " 'avoid',\n",
       " 'avoiding',\n",
       " 'avoids',\n",
       " 'awake',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'ax',\n",
       " 'axb',\n",
       " 'axiom',\n",
       " 'axiomatic',\n",
       " 'axiomatically',\n",
       " 'axis',\n",
       " 'axm',\n",
       " 'abc',\n",
       " 'ba',\n",
       " 'baby',\n",
       " 'bachelor',\n",
       " 'back',\n",
       " 'backed',\n",
       " 'backend',\n",
       " 'backends',\n",
       " 'background',\n",
       " 'backseat',\n",
       " 'backslashes',\n",
       " 'backup',\n",
       " 'backward',\n",
       " 'backwards',\n",
       " 'backword',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'baffled',\n",
       " 'baffling',\n",
       " 'bag',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balancing',\n",
       " 'ball',\n",
       " 'balloon',\n",
       " 'ballot',\n",
       " 'baloney',\n",
       " 'banach',\n",
       " 'band',\n",
       " 'bandwidth',\n",
       " 'bane',\n",
       " 'bang',\n",
       " 'bangura',\n",
       " 'bank',\n",
       " 'bankroll',\n",
       " 'banned',\n",
       " 'banner',\n",
       " 'baout',\n",
       " 'bar',\n",
       " 'barbara',\n",
       " 'barbell',\n",
       " 'barber',\n",
       " 'barely',\n",
       " 'barking',\n",
       " 'barn',\n",
       " 'barrier',\n",
       " 'bartender',\n",
       " 'bartending',\n",
       " 'bartle',\n",
       " 'baryon',\n",
       " 'baryonic',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'basketball',\n",
       " 'batch',\n",
       " 'batched',\n",
       " 'bathroom',\n",
       " 'batman',\n",
       " 'batter',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'battletoads',\n",
       " 'baye',\n",
       " 'bayes',\n",
       " 'bb',\n",
       " 'bbq',\n",
       " 'bc',\n",
       " 'bcs',\n",
       " 'bd',\n",
       " 'beach',\n",
       " 'beacon',\n",
       " 'beacuse',\n",
       " 'bead',\n",
       " 'beak',\n",
       " 'beam',\n",
       " 'beamspliter',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'beating',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'became',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'bedmas',\n",
       " 'bedroom',\n",
       " 'bedside',\n",
       " 'bee',\n",
       " 'beecroft',\n",
       " 'beer',\n",
       " 'beery',\n",
       " 'befitting',\n",
       " 'beforehand',\n",
       " 'began',\n",
       " 'begging',\n",
       " 'begginning',\n",
       " 'begin',\n",
       " 'begining',\n",
       " 'beginner',\n",
       " 'beginning',\n",
       " 'begun',\n",
       " 'behave',\n",
       " 'behaves',\n",
       " 'behaving',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'beinf',\n",
       " 'being',\n",
       " 'beleieve',\n",
       " 'belgie',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'belive',\n",
       " 'bell',\n",
       " 'belong',\n",
       " 'belonging',\n",
       " 'belongs',\n",
       " 'belt',\n",
       " 'bench',\n",
       " 'bend',\n",
       " 'bending',\n",
       " 'beneficial',\n",
       " 'benefit',\n",
       " 'benefited',\n",
       " 'benefitted',\n",
       " 'benfit',\n",
       " 'benford',\n",
       " 'benko',\n",
       " 'bent',\n",
       " 'bergon',\n",
       " 'berkeley',\n",
       " 'berkely',\n",
       " 'berkshire',\n",
       " 'berlin',\n",
       " 'bernardino',\n",
       " 'bernoulli',\n",
       " 'bertrand',\n",
       " 'bertsekas',\n",
       " 'bery',\n",
       " 'besides',\n",
       " 'bessel',\n",
       " 'besserat',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'betelgeuse',\n",
       " 'bethe',\n",
       " 'better',\n",
       " 'betting',\n",
       " 'bettor',\n",
       " 'betwen',\n",
       " 'beyond',\n",
       " 'bezos',\n",
       " 'bfs',\n",
       " 'bias',\n",
       " 'biased',\n",
       " 'bibliometric',\n",
       " 'bid',\n",
       " 'biezen',\n",
       " 'biezens',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'biharmonic',\n",
       " 'bijective',\n",
       " 'bike',\n",
       " 'billard',\n",
       " 'billiard',\n",
       " 'billion',\n",
       " 'bin',\n",
       " 'binary',\n",
       " 'binder',\n",
       " 'binding',\n",
       " 'binge',\n",
       " 'binning',\n",
       " 'binomial',\n",
       " 'bio',\n",
       " 'biochemist',\n",
       " 'bioengineering',\n",
       " 'biography',\n",
       " 'biological',\n",
       " 'biologist',\n",
       " 'biology',\n",
       " 'bioscience',\n",
       " 'biostatistics',\n",
       " 'bipartite',\n",
       " 'bipolar',\n",
       " 'birch',\n",
       " 'bird',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'biscuit',\n",
       " 'bishop',\n",
       " 'bit',\n",
       " 'bitching',\n",
       " 'bite',\n",
       " 'bitstream',\n",
       " 'bizarre',\n",
       " 'bla',\n",
       " 'black',\n",
       " 'blackboard',\n",
       " 'blackbody',\n",
       " 'blackhole',\n",
       " 'blacklight',\n",
       " 'blackmail',\n",
       " 'blacktop',\n",
       " 'blade',\n",
       " 'blah',\n",
       " 'blair',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blasted',\n",
       " 'bleak',\n",
       " 'bleeding',\n",
       " 'blender',\n",
       " 'bless',\n",
       " 'blew',\n",
       " 'blind',\n",
       " 'blindly',\n",
       " 'blinking',\n",
       " 'bloated',\n",
       " 'blob',\n",
       " 'bloch',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blog',\n",
       " 'blogging',\n",
       " 'blood',\n",
       " 'bloomer',\n",
       " 'blow',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'bloxx',\n",
       " 'blue',\n",
       " 'bluebrown',\n",
       " 'bluish',\n",
       " 'blunt',\n",
       " 'bmo',\n",
       " 'board',\n",
       " 'boarding',\n",
       " 'boast',\n",
       " 'boat',\n",
       " 'bobba',\n",
       " 'body',\n",
       " 'bogoliubov',\n",
       " 'bohm',\n",
       " 'bohmian',\n",
       " 'bohr',\n",
       " 'boi',\n",
       " 'boil',\n",
       " 'boiling',\n",
       " 'bolster',\n",
       " 'bolt',\n",
       " 'boltzmann',\n",
       " 'bomb',\n",
       " 'bombed',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'bonkers',\n",
       " 'bonnet',\n",
       " 'bonus',\n",
       " 'book',\n",
       " 'bookandtable',\n",
       " 'bookkeeper',\n",
       " ...]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_tvec_pipe.named_steps['tvec'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC Curve for Best Model (Logistic Regression)')"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_roc_curve, roc_auc_score\n",
    "plot_roc_curve(svm_tvec_pipe, X_test, y_test, label = 'LogReg (AUC = 0.96)')\n",
    "plt.plot([0, 1], [0, 1],\n",
    "         label='baseline', linestyle='--')\n",
    "plt.legend();\n",
    "plt.title('ROC Curve for Best Model (Logistic Regression)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC Curve for Best Model (Logistic Regression)')"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_roc_curve, roc_auc_score\n",
    "fig, ax = plt.subplots()\n",
    "plot_roc_curve(logreg_tvec_pipe, X_test, y_test, ax = ax)\n",
    "plot_roc_curve(svm_tvec_pipe, X_test, y_test, ax=ax)\n",
    "plt.plot([0, 1], [0, 1],\n",
    "         label='baseline', linestyle='--')\n",
    "plt.legend();\n",
    "plt.title('ROC Curve for Best Model (Logistic Regression)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9602463663013391"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, logreg_tvec_pipe.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coef = pd.DataFrame({'feature': logreg_tvec_pipe.named_steps['tvec'].get_feature_names(), 'coef': logreg_tvec_pipe.named_steps['logreg'].coef_[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6519</th>\n",
       "      <td>physic</td>\n",
       "      <td>7.895550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080</th>\n",
       "      <td>quantum</td>\n",
       "      <td>2.886535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>energy</td>\n",
       "      <td>2.794060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>force</td>\n",
       "      <td>2.355866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9341</th>\n",
       "      <td>universe</td>\n",
       "      <td>2.334521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103</th>\n",
       "      <td>light</td>\n",
       "      <td>2.319636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523</th>\n",
       "      <td>physicist</td>\n",
       "      <td>2.215318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>gravity</td>\n",
       "      <td>1.985338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8278</th>\n",
       "      <td>speed</td>\n",
       "      <td>1.828948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>velocity</td>\n",
       "      <td>1.747341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature      coef\n",
       "6519     physic  7.895550\n",
       "7080    quantum  2.886535\n",
       "2906     energy  2.794060\n",
       "3483      force  2.355866\n",
       "9341   universe  2.334521\n",
       "5103      light  2.319636\n",
       "6523  physicist  2.215318\n",
       "3867    gravity  1.985338\n",
       "8278      speed  1.828948\n",
       "9495   velocity  1.747341"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_coef.sort_values('coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feats = feat_coef.sort_values('coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6519</th>\n",
       "      <td>physic</td>\n",
       "      <td>7.895550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080</th>\n",
       "      <td>quantum</td>\n",
       "      <td>2.886535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>energy</td>\n",
       "      <td>2.794060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>force</td>\n",
       "      <td>2.355866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9341</th>\n",
       "      <td>universe</td>\n",
       "      <td>2.334521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103</th>\n",
       "      <td>light</td>\n",
       "      <td>2.319636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523</th>\n",
       "      <td>physicist</td>\n",
       "      <td>2.215318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>gravity</td>\n",
       "      <td>1.985338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8278</th>\n",
       "      <td>speed</td>\n",
       "      <td>1.828948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>velocity</td>\n",
       "      <td>1.747341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature      coef\n",
       "6519     physic  7.895550\n",
       "7080    quantum  2.886535\n",
       "2906     energy  2.794060\n",
       "3483      force  2.355866\n",
       "9341   universe  2.334521\n",
       "5103      light  2.319636\n",
       "6523  physicist  2.215318\n",
       "3867    gravity  1.985338\n",
       "8278      speed  1.828948\n",
       "9495   velocity  1.747341"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Word')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(data=feat_coef.sort_values('coef', ascending=True).head(20), x = feat_coef.sort_values('coef', ascending=True).head(20).coef, y = 'feature')\n",
    "plt.title('Top 10 r/math Words')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.ylabel('Word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_climb = pd.read_csv('./politics_politicaldiscussion_data/politics_politicaldiscussion_combined_lem_stem_67.csv', keep_default_na='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_climb = pd.read_csv('./climbing_climbharder_data/climbing_climbharder_combined_lem_stem_30.csv', keep_default_na='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_climb = df_climb['lem_text']\n",
    "y_climb = df_climb['subreddit']\n",
    "\n",
    "X_climb_train, X_climb_test, y_climb_train, y_climb_test = train_test_split(X_climb, y_climb, random_state = 42, stratify = y_climb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7460,)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_climb_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tvec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.5, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_tvec_pipe.fit(X_climb_train, y_climb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9485323683152392"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_tvec_pipe.score(X_climb_test, y_climb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.620828\n",
       "0    0.379172\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_climb_test.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coef = pd.DataFrame({'feature': logreg_tvec_pipe.named_steps['tvec'].get_feature_names(), 'coef': logreg_tvec_pipe.named_steps['logreg'].coef_[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3855</th>\n",
       "      <td>deleted</td>\n",
       "      <td>8.340702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16760</th>\n",
       "      <td>would</td>\n",
       "      <td>6.591585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>clinton</td>\n",
       "      <td>4.223025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10854</th>\n",
       "      <td>party</td>\n",
       "      <td>3.491823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15190</th>\n",
       "      <td>think</td>\n",
       "      <td>3.430626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>candidate</td>\n",
       "      <td>3.318203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14363</th>\n",
       "      <td>state</td>\n",
       "      <td>3.229296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11316</th>\n",
       "      <td>political</td>\n",
       "      <td>3.057336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8792</th>\n",
       "      <td>like</td>\n",
       "      <td>2.978058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10410</th>\n",
       "      <td>one</td>\n",
       "      <td>2.882356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9803</th>\n",
       "      <td>much</td>\n",
       "      <td>2.672219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13486</th>\n",
       "      <td>seems</td>\n",
       "      <td>2.637854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7051</th>\n",
       "      <td>hillary</td>\n",
       "      <td>2.538595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13475</th>\n",
       "      <td>see</td>\n",
       "      <td>2.494718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>also</td>\n",
       "      <td>2.488791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>effect</td>\n",
       "      <td>2.486569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8798</th>\n",
       "      <td>likely</td>\n",
       "      <td>2.393903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6525</th>\n",
       "      <td>going</td>\n",
       "      <td>2.356189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7413</th>\n",
       "      <td>impact</td>\n",
       "      <td>2.342888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9333</th>\n",
       "      <td>mean</td>\n",
       "      <td>2.337669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature      coef\n",
       "3855     deleted  8.340702\n",
       "16760      would  6.591585\n",
       "2597     clinton  4.223025\n",
       "10854      party  3.491823\n",
       "15190      think  3.430626\n",
       "2075   candidate  3.318203\n",
       "14363      state  3.229296\n",
       "11316  political  3.057336\n",
       "8792        like  2.978058\n",
       "10410        one  2.882356\n",
       "9803        much  2.672219\n",
       "13486      seems  2.637854\n",
       "7051     hillary  2.538595\n",
       "13475        see  2.494718\n",
       "508         also  2.488791\n",
       "4828      effect  2.486569\n",
       "8798      likely  2.393903\n",
       "6525       going  2.356189\n",
       "7413      impact  2.342888\n",
       "9333        mean  2.337669"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_coef.sort_values('coef', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>biden</td>\n",
       "      <td>-7.354520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15573</th>\n",
       "      <td>trump</td>\n",
       "      <td>-4.269561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363</th>\n",
       "      <td>covid</td>\n",
       "      <td>-3.327043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13314</th>\n",
       "      <td>say</td>\n",
       "      <td>-2.978628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>barrett</td>\n",
       "      <td>-2.808090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>coronavirus</td>\n",
       "      <td>-2.691245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14452</th>\n",
       "      <td>stimulus</td>\n",
       "      <td>-2.338190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10773</th>\n",
       "      <td>pandemic</td>\n",
       "      <td>-1.742796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11969</th>\n",
       "      <td>qanon</td>\n",
       "      <td>-1.725408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7254</th>\n",
       "      <td>hunter</td>\n",
       "      <td>-1.653697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6547</th>\n",
       "      <td>google</td>\n",
       "      <td>-1.615421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>final</td>\n",
       "      <td>-1.588223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8192</th>\n",
       "      <td>joe</td>\n",
       "      <td>-1.578935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12088</th>\n",
       "      <td>rally</td>\n",
       "      <td>-1.545926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>ballot</td>\n",
       "      <td>-1.511362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>amy</td>\n",
       "      <td>-1.501060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2952</th>\n",
       "      <td>coney</td>\n",
       "      <td>-1.499194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4927</th>\n",
       "      <td>email</td>\n",
       "      <td>-1.471615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>fauci</td>\n",
       "      <td>-1.389994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>mask</td>\n",
       "      <td>-1.377099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature      coef\n",
       "1490         biden -7.354520\n",
       "15573        trump -4.269561\n",
       "3363         covid -3.327043\n",
       "13314          say -2.978628\n",
       "1277       barrett -2.808090\n",
       "3266   coronavirus -2.691245\n",
       "14452     stimulus -2.338190\n",
       "10773     pandemic -1.742796\n",
       "11969        qanon -1.725408\n",
       "7254        hunter -1.653697\n",
       "6547        google -1.615421\n",
       "5837         final -1.588223\n",
       "8192           joe -1.578935\n",
       "12088        rally -1.545926\n",
       "1221        ballot -1.511362\n",
       "582            amy -1.501060\n",
       "2952         coney -1.499194\n",
       "4927         email -1.471615\n",
       "5688         fauci -1.389994\n",
       "9231          mask -1.377099"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_coef.sort_values('coef', ascending = True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'naive_bayes_cvec__alpha': 1.0,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[2]['best_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cvec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.5,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('logreg',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cvec_pipe = Pipeline([('cvec', CountVectorizer(max_df=0.5,max_features = None, min_df = 1, ngram_range=(1,1))), \n",
    "                         ('logreg', MultinomialNB())])\n",
    "nb_cvec_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9566528458349038"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cvec_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8989837615037487"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(nb_cvec_pipe, X_train, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8983050847457628"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cvec_pipe.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8994350282485876"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cvec_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 386\n",
      "True Negatives: 410\n",
      "False Positives: 33\n",
      "False Negatives: 56\n",
      "\n",
      "\n",
      "Accuracy: 0.8994350282485876\n",
      "Sensitivity/Recall (TPR): 0.8733031674208145\n",
      "Specificity (TNR): 0.9255079006772009\n",
      "Precision: 0.9212410501193318\n",
      "F1 Score: 0.8966318234610918\n",
      "\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = nb_cvec_pipe.predict(X_test)\n",
    "print(' ')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_hat).ravel()\n",
    "print('******** Test/Validation Scores ********')\n",
    "print(f'True Positives: {tp}')\n",
    "print(f'True Negatives: {tn}')\n",
    "print(f'False Positives: {fp}')\n",
    "print(f'False Negatives: {fn}')\n",
    "print('')\n",
    "print('')\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp+fn)\n",
    "print(f'Accuracy: {nb_cvec_pipe.score(X_test, y_test)}')\n",
    "print(f'Sensitivity/Recall (TPR): {recall}')\n",
    "print(f'Specificity (TNR): {tn/(tn+fp)}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'F1 Score: {2*(precision*recall)/(precision+recall)}')\n",
    "print('')      \n",
    "print('======================')\n",
    "print('')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'naive_bayes_tvec__alpha': 0.7525,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 2,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[3]['best_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tvec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.5, max_features=None,\n",
       "                                 min_df=2, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('nb',\n",
       "                 MultinomialNB(alpha=0.7525, class_prior=None,\n",
       "                               fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tvec_pipe = Pipeline([('tvec', TfidfVectorizer(max_df=0.5,max_features = None, min_df = 2, ngram_range=(1,2))),\n",
    "                         ('nb', MultinomialNB(alpha = 0.7525))])\n",
    "nb_tvec_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698454579721071"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tvec_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8903954802259887"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tvec_pipe.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8779661016949153"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tvec_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svm_cvec__C': 10,\n",
       " 'svm_cvec__gamma': 'scale',\n",
       " 'svm_cvec__kernel': 'rbf',\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[4]['best_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cvec_pipe = Pipeline([('cvec', CountVectorizer(max_df=0.5,max_features = None, min_df = 1, ngram_range=(1,2))), \n",
    "                         ('svm', SVC(C = 10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cvec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.5,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('svm',\n",
       "                 SVC(C=10, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cvec_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9954768186958161"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cvec_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8677966101694915"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cvec_pipe.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8564971751412429"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cvec_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic_regression_cvec__C': 0.01,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 10,\n",
       " 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[5]['best_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tvec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.5, max_features=None,\n",
       "                                 min_df=10, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('ss',\n",
       "                 StandardScaler(copy=True, with_mean=False, with_std=True)),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(C=0.01, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cvec_pipe = Pipeline([('tvec', TfidfVectorizer(max_df=0.5,max_features = None, min_df = 10, ngram_range=(1,1))), \n",
    "                             ('ss', StandardScaler(with_mean=False)),\n",
    "                         ('logreg', LogisticRegression(C = 0.01))])\n",
    "logreg_cvec_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9879381831888429"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cvec_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8497175141242937"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cvec_pipe.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8576271186440678"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cvec_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('./math_physics_data/math_physics_combined_lem_stem_843.csv',keep_default_na=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        0\n",
       "selftext     0\n",
       "text         0\n",
       "lem_text     0\n",
       "stem_text    0\n",
       "subreddit    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = df_all['lem_text']\n",
    "y_all = df_all['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8209957165929359"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cvec_pipe.score(X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2653,)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.516023\n",
       "1    0.483977\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scitech = pd.read_csv('./science_technology_data/science_technology_combined_lem_stem_50.csv', keep_default_na=False)\n",
    "X_scitech = df_scitech['lem_text']\n",
    "y_scitech = df_scitech['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tvec_pipe_sci = Pipeline([('tvec', TfidfVectorizer(max_df=0.5,max_features = None, min_df = 1, ngram_range=(1,2))), \n",
    "                         ('svm', SVC(C = 10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sci_train, X_sci_test, y_sci_train, y_sci_test = train_test_split(X_scitech, y_scitech, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tvec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.5, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('svm',\n",
       "                 SVC(C=10, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_tvec_pipe_sci.fit(X_sci_train, y_sci_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_tvec_pipe_sci.score(X_sci_train, y_sci_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9165571616294349"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_tvec_pipe_sci.score(X_sci_test, y_sci_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.6885670601317253\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 310\n",
      "True Negatives: 209\n",
      "False Positives: 150\n",
      "False Negatives: 52\n",
      "\n",
      "\n",
      "Accuracy: 0.7198335644937587\n",
      "Sensitivity/Recall (TPR): 0.856353591160221\n",
      "Specificity (TNR): 0.5821727019498607\n",
      "Precision: 0.6739130434782609\n",
      "F1 Score: 0.754257907542579\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8903280301086305\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 326\n",
      "True Negatives: 324\n",
      "False Positives: 35\n",
      "False Negatives: 36\n",
      "\n",
      "\n",
      "Accuracy: 0.9015256588072122\n",
      "Sensitivity/Recall (TPR): 0.9005524861878453\n",
      "Specificity (TNR): 0.9025069637883009\n",
      "Precision: 0.9030470914127424\n",
      "F1 Score: 0.9017980636237898\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8708953468480027\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 323\n",
      "True Negatives: 316\n",
      "False Positives: 43\n",
      "False Negatives: 39\n",
      "\n",
      "\n",
      "Accuracy: 0.8862690707350902\n",
      "Sensitivity/Recall (TPR): 0.8922651933701657\n",
      "Specificity (TNR): 0.8802228412256268\n",
      "Precision: 0.8825136612021858\n",
      "F1 Score: 0.8873626373626373\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.7973163116927551\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 297\n",
      "True Negatives: 296\n",
      "False Positives: 63\n",
      "False Negatives: 65\n",
      "\n",
      "\n",
      "Accuracy: 0.8224687933425797\n",
      "Sensitivity/Recall (TPR): 0.8204419889502762\n",
      "Specificity (TNR): 0.8245125348189415\n",
      "Precision: 0.825\n",
      "F1 Score: 0.8227146814404431\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.ensemble._bagging.BaggingClassifier'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8172205115045761\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 292\n",
      "True Negatives: 310\n",
      "False Positives: 49\n",
      "False Negatives: 70\n",
      "\n",
      "\n",
      "Accuracy: 0.8349514563106796\n",
      "Sensitivity/Recall (TPR): 0.8066298342541437\n",
      "Specificity (TNR): 0.8635097493036211\n",
      "Precision: 0.8563049853372434\n",
      "F1 Score: 0.8307254623044097\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8500705671028997\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 316\n",
      "True Negatives: 317\n",
      "False Positives: 42\n",
      "False Negatives: 46\n",
      "\n",
      "\n",
      "Accuracy: 0.8779472954230236\n",
      "Sensitivity/Recall (TPR): 0.8729281767955801\n",
      "Specificity (TNR): 0.883008356545961\n",
      "Precision: 0.88268156424581\n",
      "F1 Score: 0.8777777777777777\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.ensemble._forest.ExtraTreesClassifier'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8403494140792063\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 307\n",
      "True Negatives: 324\n",
      "False Positives: 35\n",
      "False Negatives: 55\n",
      "\n",
      "\n",
      "Accuracy: 0.8751733703190014\n",
      "Sensitivity/Recall (TPR): 0.8480662983425414\n",
      "Specificity (TNR): 0.9025069637883009\n",
      "Precision: 0.8976608187134503\n",
      "F1 Score: 0.8721590909090909\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 1.0, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8075014968779403\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 275\n",
      "True Negatives: 318\n",
      "False Positives: 41\n",
      "False Negatives: 87\n",
      "\n",
      "\n",
      "Accuracy: 0.8224687933425797\n",
      "Sensitivity/Recall (TPR): 0.7596685082872928\n",
      "Specificity (TNR): 0.8857938718662952\n",
      "Precision: 0.870253164556962\n",
      "F1 Score: 0.8112094395280236\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 1.0, 'vect__min_df': 1, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8311029852022923\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 339\n",
      "True Negatives: 287\n",
      "False Positives: 72\n",
      "False Negatives: 23\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8682385575589459\n",
      "Sensitivity/Recall (TPR): 0.93646408839779\n",
      "Specificity (TNR): 0.7994428969359332\n",
      "Precision: 0.8248175182481752\n",
      "F1 Score: 0.8771021992238033\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.svm._classes.SVC'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.808418869215636\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 325\n",
      "True Negatives: 278\n",
      "False Positives: 81\n",
      "False Negatives: 37\n",
      "\n",
      "\n",
      "Accuracy: 0.8363384188626907\n",
      "Sensitivity/Recall (TPR): 0.8977900552486188\n",
      "Specificity (TNR): 0.7743732590529248\n",
      "Precision: 0.8004926108374384\n",
      "F1 Score: 0.8463541666666665\n",
      "\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_scores = pipe_gridsearch(pipelines, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_scores_cvec = search_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'knn_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.6885670601317253,\n",
       "  'val_score': 0.7198335644937587,\n",
       "  'tp': 310,\n",
       "  'tn': 209,\n",
       "  'fp': 150,\n",
       "  'fn': 52},\n",
       " {'name': 'naive_bayes_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8903280301086305,\n",
       "  'val_score': 0.9015256588072122,\n",
       "  'tp': 326,\n",
       "  'tn': 324,\n",
       "  'fp': 35,\n",
       "  'fn': 36},\n",
       " {'name': 'logistic_regression_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.8708953468480027,\n",
       "  'val_score': 0.8862690707350902,\n",
       "  'tp': 323,\n",
       "  'tn': 316,\n",
       "  'fp': 43,\n",
       "  'fn': 39},\n",
       " {'name': 'cart_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.7973163116927551,\n",
       "  'val_score': 0.8224687933425797,\n",
       "  'tp': 297,\n",
       "  'tn': 296,\n",
       "  'fp': 63,\n",
       "  'fn': 65},\n",
       " {'name': 'bagging_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.8172205115045761,\n",
       "  'val_score': 0.8349514563106796,\n",
       "  'tp': 292,\n",
       "  'tn': 310,\n",
       "  'fp': 49,\n",
       "  'fn': 70},\n",
       " {'name': 'random_forest_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8500705671028997,\n",
       "  'val_score': 0.8779472954230236,\n",
       "  'tp': 316,\n",
       "  'tn': 317,\n",
       "  'fp': 42,\n",
       "  'fn': 46},\n",
       " {'name': 'extratrees_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8403494140792063,\n",
       "  'val_score': 0.8751733703190014,\n",
       "  'tp': 307,\n",
       "  'tn': 324,\n",
       "  'fp': 35,\n",
       "  'fn': 55},\n",
       " {'name': 'adaboost_cvec',\n",
       "  'best_params': {'vect__max_df': 1.0,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8075014968779403,\n",
       "  'val_score': 0.8224687933425797,\n",
       "  'tp': 275,\n",
       "  'tn': 318,\n",
       "  'fp': 41,\n",
       "  'fn': 87},\n",
       " {'name': 'gradient_boost_cvec',\n",
       "  'best_params': {'vect__max_df': 1.0,\n",
       "   'vect__min_df': 1,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8311029852022923,\n",
       "  'val_score': 0.8682385575589459,\n",
       "  'tp': 339,\n",
       "  'tn': 287,\n",
       "  'fp': 72,\n",
       "  'fn': 23},\n",
       " {'name': 'svm_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.808418869215636,\n",
       "  'val_score': 0.8363384188626907,\n",
       "  'tp': 325,\n",
       "  'tn': 278,\n",
       "  'fp': 81,\n",
       "  'fn': 37}]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_scores_cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines_tvec = [\n",
    "    {\n",
    "        'name': 'knn_tvec', \n",
    "        'vect': TfidfVectorizer(), \n",
    "        'ss' : StandardScaler(with_mean = False),  #https://stackoverflow.com/questions/36675022/do-you-need-to-scale-vectorizers-in-sklearn\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'param_grid' : {\n",
    " #               'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2],\n",
    "                'vect__max_df': [.9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)]\n",
    "#                'knn_tvec__n_neighbors' : [5, 10]\n",
    "            }\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        'name': 'naive_bayes_tvec', \n",
    "        'vect': TfidfVectorizer(), \n",
    "        'model': MultinomialNB(), \n",
    "        'param_grid' : {\n",
    "#                'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2],\n",
    "                'vect__max_df': [.9, 1.0]\n",
    "               # 'vect__ngram_range': [(1,1), (1,2)]\n",
    "            }\n",
    "        \n",
    "    }, \n",
    "    {\n",
    "        'name': 'logistic_regression_tvec', \n",
    "        'vect': TfidfVectorizer(),\n",
    "        'ss' : StandardScaler(with_mean = False),\n",
    "        'model': LogisticRegression(max_iter=1000000), \n",
    "        'param_grid' : {\n",
    " #               'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2],\n",
    "                'vect__max_df': [.9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)]\n",
    "               # 'logistic_regression_tvec__C' : np.logspace(-1,1,3)\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        'name': 'cart_tvec', \n",
    "        'vect': TfidfVectorizer(), \n",
    "        'model': DecisionTreeClassifier(random_state = 42), \n",
    "        'param_grid' : {\n",
    " #               'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2],\n",
    "                'vect__max_df': [.9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)]\n",
    "               # 'cart_tvec__max_depth': [1, 3, 100, 500]\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        'name': 'bagging_tvec', \n",
    "        'vect': TfidfVectorizer(), \n",
    "        'model': BaggingClassifier(random_state = 42), \n",
    "        'param_grid' : {\n",
    "#                'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2],\n",
    "                'vect__max_df': [.9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)]\n",
    "               # 'bagging_tvec__n_estimators' : [10, 20, 100]\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        'name': 'random_forest_tvec', \n",
    "        'vect': TfidfVectorizer(), \n",
    "        'model': RandomForestClassifier(random_state = 42), \n",
    "        'param_grid' : {\n",
    " #               'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2],\n",
    "                'vect__max_df': [.9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)] \n",
    "               # 'random_forest_tvec__max_depth': [1, 3, 100, 500]\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        'name': 'extratrees_tvec', \n",
    "        'vect': TfidfVectorizer(), \n",
    "        'model': ExtraTreesClassifier(random_state = 42), \n",
    "        'param_grid' : {\n",
    "#                'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2],\n",
    "                'vect__max_df': [.9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)]\n",
    "             #   'extratrees_tvec__max_depth': [1, 3, 100, 500]\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        'name': 'adaboost_tvec', \n",
    "        'vect': TfidfVectorizer(), \n",
    "        'model': AdaBoostClassifier(base_estimator=DecisionTreeClassifier()), \n",
    "        'param_grid' : {\n",
    "#                'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2],\n",
    "                'vect__max_df': [.9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)]\n",
    "               # 'adaboost_tvec__base_estimator__max_depth': [1, 3, 100, 500],\n",
    "               # 'adaboost_tvec__learning_rate': [.9, 1.]\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        'name': 'gradient_boost_tvec', \n",
    "        'vect': TfidfVectorizer(), \n",
    "        'model': GradientBoostingClassifier(), \n",
    "        'param_grid' : {\n",
    "  #              'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2],\n",
    "                'vect__max_df': [.9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)]\n",
    "               # 'gradient_boost_tvec__max_depth': [1, 3, 100, 500],\n",
    "               # 'gradient_boost_tvec__learning_rate': [.08, .1]\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        'name': 'svm_tvec', \n",
    "        'vect': TfidfVectorizer(), \n",
    "        'model': SVC(), \n",
    "        'param_grid' : {\n",
    "#                'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2],\n",
    "                'vect__max_df': [.9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)] \n",
    "              #  'svm_tvec__C': [.5, .8, 1.0, 1.2], \n",
    "              #  'svm_tvec__kernel' : ['poly', 'rbf']\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.5404969634761783\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 263\n",
      "True Negatives: 109\n",
      "False Positives: 250\n",
      "False Negatives: 99\n",
      "\n",
      "\n",
      "Accuracy: 0.5159500693481276\n",
      "Sensitivity/Recall (TPR): 0.7265193370165746\n",
      "Specificity (TNR): 0.30362116991643456\n",
      "Precision: 0.5126705653021443\n",
      "F1 Score: 0.6011428571428571\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 2}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8769085193738773\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 311\n",
      "True Negatives: 338\n",
      "False Positives: 21\n",
      "False Negatives: 51\n",
      "\n",
      "\n",
      "Accuracy: 0.9001386962552012\n",
      "Sensitivity/Recall (TPR): 0.8591160220994475\n",
      "Specificity (TNR): 0.9415041782729805\n",
      "Precision: 0.9367469879518072\n",
      "F1 Score: 0.8962536023054755\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 1, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8431346762466856\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 316\n",
      "True Negatives: 308\n",
      "False Positives: 51\n",
      "False Negatives: 46\n",
      "\n",
      "\n",
      "Accuracy: 0.8654646324549237\n",
      "Sensitivity/Recall (TPR): 0.8729281767955801\n",
      "Specificity (TNR): 0.8579387186629527\n",
      "Precision: 0.8610354223433242\n",
      "F1 Score: 0.8669410150891631\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.7820556410914379\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 289\n",
      "True Negatives: 286\n",
      "False Positives: 73\n",
      "False Negatives: 73\n",
      "\n",
      "\n",
      "Accuracy: 0.79750346740638\n",
      "Sensitivity/Recall (TPR): 0.7983425414364641\n",
      "Specificity (TNR): 0.7966573816155988\n",
      "Precision: 0.7983425414364641\n",
      "F1 Score: 0.7983425414364641\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.ensemble._bagging.BaggingClassifier'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8116713711401932\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 283\n",
      "True Negatives: 300\n",
      "False Positives: 59\n",
      "False Negatives: 79\n",
      "\n",
      "\n",
      "Accuracy: 0.8085991678224688\n",
      "Sensitivity/Recall (TPR): 0.7817679558011049\n",
      "Specificity (TNR): 0.8356545961002786\n",
      "Precision: 0.827485380116959\n",
      "F1 Score: 0.8039772727272728\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8546948507398853\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 314\n",
      "True Negatives: 317\n",
      "False Positives: 42\n",
      "False Negatives: 48\n",
      "\n",
      "\n",
      "Accuracy: 0.8751733703190014\n",
      "Sensitivity/Recall (TPR): 0.8674033149171271\n",
      "Specificity (TNR): 0.883008356545961\n",
      "Precision: 0.8820224719101124\n",
      "F1 Score: 0.8746518105849583\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.ensemble._forest.ExtraTreesClassifier'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8546948507398854\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 317\n",
      "True Negatives: 318\n",
      "False Positives: 41\n",
      "False Negatives: 45\n",
      "\n",
      "\n",
      "Accuracy: 0.8807212205270458\n",
      "Sensitivity/Recall (TPR): 0.8756906077348067\n",
      "Specificity (TNR): 0.8857938718662952\n",
      "Precision: 0.8854748603351955\n",
      "F1 Score: 0.8805555555555555\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 1, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.7959306303994527\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 264\n",
      "True Negatives: 312\n",
      "False Positives: 47\n",
      "False Negatives: 98\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7988904299583911\n",
      "Sensitivity/Recall (TPR): 0.7292817679558011\n",
      "Specificity (TNR): 0.8690807799442897\n",
      "Precision: 0.8488745980707395\n",
      "F1 Score: 0.7845468053491829\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 1, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.838503977418527\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 336\n",
      "True Negatives: 288\n",
      "False Positives: 71\n",
      "False Negatives: 26\n",
      "\n",
      "\n",
      "Accuracy: 0.8654646324549237\n",
      "Sensitivity/Recall (TPR): 0.9281767955801105\n",
      "Specificity (TNR): 0.8022284122562674\n",
      "Precision: 0.8255528255528255\n",
      "F1 Score: 0.8738621586475942\n",
      "\n",
      "======================\n",
      "\n",
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.svm._classes.SVC'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'vect__max_df': 0.9, 'vect__min_df': 1, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8949587289367891\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 317\n",
      "True Negatives: 331\n",
      "False Positives: 28\n",
      "False Negatives: 45\n",
      "\n",
      "\n",
      "Accuracy: 0.8987517337031901\n",
      "Sensitivity/Recall (TPR): 0.8756906077348067\n",
      "Specificity (TNR): 0.9220055710306406\n",
      "Precision: 0.9188405797101449\n",
      "F1 Score: 0.8967468175388967\n",
      "\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_scores_tvec = pipe_gridsearch(pipelines_tvec, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'knn_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.5404969634761783,\n",
       "  'val_score': 0.5159500693481276,\n",
       "  'tp': 263,\n",
       "  'tn': 109,\n",
       "  'fp': 250,\n",
       "  'fn': 99},\n",
       " {'name': 'naive_bayes_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9, 'vect__min_df': 2},\n",
       "  'cv_score': 0.8769085193738773,\n",
       "  'val_score': 0.9001386962552012,\n",
       "  'tp': 311,\n",
       "  'tn': 338,\n",
       "  'fp': 21,\n",
       "  'fn': 51},\n",
       " {'name': 'logistic_regression_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 1,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8431346762466856,\n",
       "  'val_score': 0.8654646324549237,\n",
       "  'tp': 316,\n",
       "  'tn': 308,\n",
       "  'fp': 51,\n",
       "  'fn': 46},\n",
       " {'name': 'cart_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.7820556410914379,\n",
       "  'val_score': 0.79750346740638,\n",
       "  'tp': 289,\n",
       "  'tn': 286,\n",
       "  'fp': 73,\n",
       "  'fn': 73},\n",
       " {'name': 'bagging_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8116713711401932,\n",
       "  'val_score': 0.8085991678224688,\n",
       "  'tp': 283,\n",
       "  'tn': 300,\n",
       "  'fp': 59,\n",
       "  'fn': 79},\n",
       " {'name': 'random_forest_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8546948507398853,\n",
       "  'val_score': 0.8751733703190014,\n",
       "  'tp': 314,\n",
       "  'tn': 317,\n",
       "  'fp': 42,\n",
       "  'fn': 48},\n",
       " {'name': 'extratrees_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8546948507398854,\n",
       "  'val_score': 0.8807212205270458,\n",
       "  'tp': 317,\n",
       "  'tn': 318,\n",
       "  'fp': 41,\n",
       "  'fn': 45},\n",
       " {'name': 'adaboost_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 1,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.7959306303994527,\n",
       "  'val_score': 0.7988904299583911,\n",
       "  'tp': 264,\n",
       "  'tn': 312,\n",
       "  'fp': 47,\n",
       "  'fn': 98},\n",
       " {'name': 'gradient_boost_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 1,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.838503977418527,\n",
       "  'val_score': 0.8654646324549237,\n",
       "  'tp': 336,\n",
       "  'tn': 288,\n",
       "  'fp': 71,\n",
       "  'fn': 26},\n",
       " {'name': 'svm_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 1,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8949587289367891,\n",
       "  'val_score': 0.8987517337031901,\n",
       "  'tp': 317,\n",
       "  'tn': 331,\n",
       "  'fp': 28,\n",
       "  'fn': 45}]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_scores_tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>best_params</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naive_bayes_cvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...</td>\n",
       "      <td>0.890328</td>\n",
       "      <td>0.901526</td>\n",
       "      <td>326</td>\n",
       "      <td>324</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>naive_bayes_tvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 2}</td>\n",
       "      <td>0.876909</td>\n",
       "      <td>0.900139</td>\n",
       "      <td>311</td>\n",
       "      <td>338</td>\n",
       "      <td>21</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>svm_tvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 1, 'vect...</td>\n",
       "      <td>0.894959</td>\n",
       "      <td>0.898752</td>\n",
       "      <td>317</td>\n",
       "      <td>331</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression_cvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...</td>\n",
       "      <td>0.870895</td>\n",
       "      <td>0.886269</td>\n",
       "      <td>323</td>\n",
       "      <td>316</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>extratrees_tvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...</td>\n",
       "      <td>0.854695</td>\n",
       "      <td>0.880721</td>\n",
       "      <td>317</td>\n",
       "      <td>318</td>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random_forest_cvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...</td>\n",
       "      <td>0.850071</td>\n",
       "      <td>0.877947</td>\n",
       "      <td>316</td>\n",
       "      <td>317</td>\n",
       "      <td>42</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>random_forest_tvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...</td>\n",
       "      <td>0.854695</td>\n",
       "      <td>0.875173</td>\n",
       "      <td>314</td>\n",
       "      <td>317</td>\n",
       "      <td>42</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>extratrees_cvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...</td>\n",
       "      <td>0.840349</td>\n",
       "      <td>0.875173</td>\n",
       "      <td>307</td>\n",
       "      <td>324</td>\n",
       "      <td>35</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gradient_boost_cvec</td>\n",
       "      <td>{'vect__max_df': 1.0, 'vect__min_df': 1, 'vect...</td>\n",
       "      <td>0.831103</td>\n",
       "      <td>0.868239</td>\n",
       "      <td>339</td>\n",
       "      <td>287</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>logistic_regression_tvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 1, 'vect...</td>\n",
       "      <td>0.843135</td>\n",
       "      <td>0.865465</td>\n",
       "      <td>316</td>\n",
       "      <td>308</td>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gradient_boost_tvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 1, 'vect...</td>\n",
       "      <td>0.838504</td>\n",
       "      <td>0.865465</td>\n",
       "      <td>336</td>\n",
       "      <td>288</td>\n",
       "      <td>71</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm_cvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...</td>\n",
       "      <td>0.808419</td>\n",
       "      <td>0.836338</td>\n",
       "      <td>325</td>\n",
       "      <td>278</td>\n",
       "      <td>81</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bagging_cvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...</td>\n",
       "      <td>0.817221</td>\n",
       "      <td>0.834951</td>\n",
       "      <td>292</td>\n",
       "      <td>310</td>\n",
       "      <td>49</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost_cvec</td>\n",
       "      <td>{'vect__max_df': 1.0, 'vect__min_df': 2, 'vect...</td>\n",
       "      <td>0.807501</td>\n",
       "      <td>0.822469</td>\n",
       "      <td>275</td>\n",
       "      <td>318</td>\n",
       "      <td>41</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart_cvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...</td>\n",
       "      <td>0.797316</td>\n",
       "      <td>0.822469</td>\n",
       "      <td>297</td>\n",
       "      <td>296</td>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bagging_tvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...</td>\n",
       "      <td>0.811671</td>\n",
       "      <td>0.808599</td>\n",
       "      <td>283</td>\n",
       "      <td>300</td>\n",
       "      <td>59</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>adaboost_tvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 1, 'vect...</td>\n",
       "      <td>0.795931</td>\n",
       "      <td>0.798890</td>\n",
       "      <td>264</td>\n",
       "      <td>312</td>\n",
       "      <td>47</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cart_tvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...</td>\n",
       "      <td>0.782056</td>\n",
       "      <td>0.797503</td>\n",
       "      <td>289</td>\n",
       "      <td>286</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn_cvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...</td>\n",
       "      <td>0.688567</td>\n",
       "      <td>0.719834</td>\n",
       "      <td>310</td>\n",
       "      <td>209</td>\n",
       "      <td>150</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>knn_tvec</td>\n",
       "      <td>{'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...</td>\n",
       "      <td>0.540497</td>\n",
       "      <td>0.515950</td>\n",
       "      <td>263</td>\n",
       "      <td>109</td>\n",
       "      <td>250</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  \\\n",
       "1           naive_bayes_cvec   \n",
       "11          naive_bayes_tvec   \n",
       "19                  svm_tvec   \n",
       "2   logistic_regression_cvec   \n",
       "16           extratrees_tvec   \n",
       "5         random_forest_cvec   \n",
       "15        random_forest_tvec   \n",
       "6            extratrees_cvec   \n",
       "8        gradient_boost_cvec   \n",
       "12  logistic_regression_tvec   \n",
       "18       gradient_boost_tvec   \n",
       "9                   svm_cvec   \n",
       "4               bagging_cvec   \n",
       "7              adaboost_cvec   \n",
       "3                  cart_cvec   \n",
       "14              bagging_tvec   \n",
       "17             adaboost_tvec   \n",
       "13                 cart_tvec   \n",
       "0                   knn_cvec   \n",
       "10                  knn_tvec   \n",
       "\n",
       "                                          best_params  cv_score  val_score  \\\n",
       "1   {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...  0.890328   0.901526   \n",
       "11           {'vect__max_df': 0.9, 'vect__min_df': 2}  0.876909   0.900139   \n",
       "19  {'vect__max_df': 0.9, 'vect__min_df': 1, 'vect...  0.894959   0.898752   \n",
       "2   {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...  0.870895   0.886269   \n",
       "16  {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...  0.854695   0.880721   \n",
       "5   {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...  0.850071   0.877947   \n",
       "15  {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...  0.854695   0.875173   \n",
       "6   {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...  0.840349   0.875173   \n",
       "8   {'vect__max_df': 1.0, 'vect__min_df': 1, 'vect...  0.831103   0.868239   \n",
       "12  {'vect__max_df': 0.9, 'vect__min_df': 1, 'vect...  0.843135   0.865465   \n",
       "18  {'vect__max_df': 0.9, 'vect__min_df': 1, 'vect...  0.838504   0.865465   \n",
       "9   {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...  0.808419   0.836338   \n",
       "4   {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...  0.817221   0.834951   \n",
       "7   {'vect__max_df': 1.0, 'vect__min_df': 2, 'vect...  0.807501   0.822469   \n",
       "3   {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...  0.797316   0.822469   \n",
       "14  {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...  0.811671   0.808599   \n",
       "17  {'vect__max_df': 0.9, 'vect__min_df': 1, 'vect...  0.795931   0.798890   \n",
       "13  {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...  0.782056   0.797503   \n",
       "0   {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...  0.688567   0.719834   \n",
       "10  {'vect__max_df': 0.9, 'vect__min_df': 2, 'vect...  0.540497   0.515950   \n",
       "\n",
       "     tp   tn   fp  fn  \n",
       "1   326  324   35  36  \n",
       "11  311  338   21  51  \n",
       "19  317  331   28  45  \n",
       "2   323  316   43  39  \n",
       "16  317  318   41  45  \n",
       "5   316  317   42  46  \n",
       "15  314  317   42  48  \n",
       "6   307  324   35  55  \n",
       "8   339  287   72  23  \n",
       "12  316  308   51  46  \n",
       "18  336  288   71  26  \n",
       "9   325  278   81  37  \n",
       "4   292  310   49  70  \n",
       "7   275  318   41  87  \n",
       "3   297  296   63  65  \n",
       "14  283  300   59  79  \n",
       "17  264  312   47  98  \n",
       "13  289  286   73  73  \n",
       "0   310  209  150  52  \n",
       "10  263  109  250  99  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores = search_scores_cvec +  search_scores_tvec\n",
    "pd.DataFrame(all_scores).sort_values('val_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'knn_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.6885670601317253,\n",
       "  'val_score': 0.7198335644937587,\n",
       "  'tp': 310,\n",
       "  'tn': 209,\n",
       "  'fp': 150,\n",
       "  'fn': 52},\n",
       " {'name': 'naive_bayes_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8903280301086305,\n",
       "  'val_score': 0.9015256588072122,\n",
       "  'tp': 326,\n",
       "  'tn': 324,\n",
       "  'fp': 35,\n",
       "  'fn': 36},\n",
       " {'name': 'logistic_regression_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.8708953468480027,\n",
       "  'val_score': 0.8862690707350902,\n",
       "  'tp': 323,\n",
       "  'tn': 316,\n",
       "  'fp': 43,\n",
       "  'fn': 39},\n",
       " {'name': 'cart_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.7973163116927551,\n",
       "  'val_score': 0.8224687933425797,\n",
       "  'tp': 297,\n",
       "  'tn': 296,\n",
       "  'fp': 63,\n",
       "  'fn': 65},\n",
       " {'name': 'bagging_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.8172205115045761,\n",
       "  'val_score': 0.8349514563106796,\n",
       "  'tp': 292,\n",
       "  'tn': 310,\n",
       "  'fp': 49,\n",
       "  'fn': 70},\n",
       " {'name': 'random_forest_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8500705671028997,\n",
       "  'val_score': 0.8779472954230236,\n",
       "  'tp': 316,\n",
       "  'tn': 317,\n",
       "  'fp': 42,\n",
       "  'fn': 46},\n",
       " {'name': 'extratrees_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8403494140792063,\n",
       "  'val_score': 0.8751733703190014,\n",
       "  'tp': 307,\n",
       "  'tn': 324,\n",
       "  'fp': 35,\n",
       "  'fn': 55},\n",
       " {'name': 'adaboost_cvec',\n",
       "  'best_params': {'vect__max_df': 1.0,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8075014968779403,\n",
       "  'val_score': 0.8224687933425797,\n",
       "  'tp': 275,\n",
       "  'tn': 318,\n",
       "  'fp': 41,\n",
       "  'fn': 87},\n",
       " {'name': 'gradient_boost_cvec',\n",
       "  'best_params': {'vect__max_df': 1.0,\n",
       "   'vect__min_df': 1,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8311029852022923,\n",
       "  'val_score': 0.8682385575589459,\n",
       "  'tp': 339,\n",
       "  'tn': 287,\n",
       "  'fp': 72,\n",
       "  'fn': 23},\n",
       " {'name': 'svm_cvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.808418869215636,\n",
       "  'val_score': 0.8363384188626907,\n",
       "  'tp': 325,\n",
       "  'tn': 278,\n",
       "  'fp': 81,\n",
       "  'fn': 37},\n",
       " {'name': 'knn_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.5404969634761783,\n",
       "  'val_score': 0.5159500693481276,\n",
       "  'tp': 263,\n",
       "  'tn': 109,\n",
       "  'fp': 250,\n",
       "  'fn': 99},\n",
       " {'name': 'naive_bayes_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9, 'vect__min_df': 2},\n",
       "  'cv_score': 0.8769085193738773,\n",
       "  'val_score': 0.9001386962552012,\n",
       "  'tp': 311,\n",
       "  'tn': 338,\n",
       "  'fp': 21,\n",
       "  'fn': 51},\n",
       " {'name': 'logistic_regression_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 1,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8431346762466856,\n",
       "  'val_score': 0.8654646324549237,\n",
       "  'tp': 316,\n",
       "  'tn': 308,\n",
       "  'fp': 51,\n",
       "  'fn': 46},\n",
       " {'name': 'cart_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.7820556410914379,\n",
       "  'val_score': 0.79750346740638,\n",
       "  'tp': 289,\n",
       "  'tn': 286,\n",
       "  'fp': 73,\n",
       "  'fn': 73},\n",
       " {'name': 'bagging_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8116713711401932,\n",
       "  'val_score': 0.8085991678224688,\n",
       "  'tp': 283,\n",
       "  'tn': 300,\n",
       "  'fp': 59,\n",
       "  'fn': 79},\n",
       " {'name': 'random_forest_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8546948507398853,\n",
       "  'val_score': 0.8751733703190014,\n",
       "  'tp': 314,\n",
       "  'tn': 317,\n",
       "  'fp': 42,\n",
       "  'fn': 48},\n",
       " {'name': 'extratrees_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 2,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8546948507398854,\n",
       "  'val_score': 0.8807212205270458,\n",
       "  'tp': 317,\n",
       "  'tn': 318,\n",
       "  'fp': 41,\n",
       "  'fn': 45},\n",
       " {'name': 'adaboost_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 1,\n",
       "   'vect__ngram_range': (1, 1)},\n",
       "  'cv_score': 0.7959306303994527,\n",
       "  'val_score': 0.7988904299583911,\n",
       "  'tp': 264,\n",
       "  'tn': 312,\n",
       "  'fp': 47,\n",
       "  'fn': 98},\n",
       " {'name': 'gradient_boost_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 1,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.838503977418527,\n",
       "  'val_score': 0.8654646324549237,\n",
       "  'tp': 336,\n",
       "  'tn': 288,\n",
       "  'fp': 71,\n",
       "  'fn': 26},\n",
       " {'name': 'svm_tvec',\n",
       "  'best_params': {'vect__max_df': 0.9,\n",
       "   'vect__min_df': 1,\n",
       "   'vect__ngram_range': (1, 2)},\n",
       "  'cv_score': 0.8949587289367891,\n",
       "  'val_score': 0.8987517337031901,\n",
       "  'tp': 317,\n",
       "  'tn': 331,\n",
       "  'fp': 28,\n",
       "  'fn': 45}]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose the top 5 models:\n",
    "# Naive bayes with cvec\n",
    "# SVM with tvec\n",
    "# logreg wih cvec\n",
    "# extratrees with tvec\n",
    "# randomforest with cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [\n",
    "    \n",
    "    {\n",
    "        'name': 'naive_bayes_cvec', \n",
    "        'vect': CountVectorizer(stop_words='english'), \n",
    "        'model': MultinomialNB(), \n",
    "        'param_grid' : {\n",
    "                'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2],\n",
    "                'vect__max_df': [.9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)],\n",
    "                'naive_bayes_cvec__alpha' : np.linspace(0, 1, 10)\n",
    "            }\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        'name': 'naive_bayes_tvec', \n",
    "        'vect': TfidfVectorizer(stop_words='english'), \n",
    "        'model': MultinomialNB(), \n",
    "        'param_grid' : {\n",
    "                'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2],\n",
    "                'vect__max_df': [.9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)],\n",
    "                'naive_bayes_cvec__alpha' : np.linspace(0, 1, 10)\n",
    "            }\n",
    "        \n",
    "    }, \n",
    "    {\n",
    "        'name': 'svm_cvec', \n",
    "        'vect': CountVectorizer(stop_words='english'), \n",
    "        'model': SVC(), \n",
    "        'param_grid' : {\n",
    "#                'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2, 5],\n",
    "                'vect__max_df': [.85, .9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)], \n",
    "                'svm_tvec__C': np.linspace(.001, 10, 10),\n",
    "                'svm_tvec__gamma': ['auto', 'scale', .01,1, 10 ], \n",
    "                'svm_tvec__kernel' : ['poly', 'rbf']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'svm_tvec', \n",
    "        'vect': TfidfVectorizer(stop_words='english'), \n",
    "        'model': SVC(), \n",
    "        'param_grid' : {\n",
    "#                'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2, 5],\n",
    "                'vect__max_df': [.85, .9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)], \n",
    "                'svm_tvec__C': np.linspace(.001, 10, 10),\n",
    "                'svm_tvec__gamma': ['auto', 'scale', .01,1, 10 ], \n",
    "                'svm_tvec__kernel' : ['poly', 'rbf']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'logistic_regression_cvec', \n",
    "        'vect': CountVectorizer(stop_words='english'),\n",
    "        'ss' : StandardScaler(with_mean = False),\n",
    "        'model': LogisticRegression(max_iter=1000000), \n",
    "        'param_grid' : {\n",
    " #               'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2, 5, 10],\n",
    "                'vect__max_df': [.8, .85, .9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)],\n",
    "                'logistic_regression_cvec__C' : np.logspace(-4,4,9), \n",
    "                'logistic_regression_cvec__penalty' : ['l1', 'l2']\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        'name': 'logistic_regression_tvec_no_ss', \n",
    "        'vect': TfidfVectorizer(stop_words='english'),\n",
    "        'model': LogisticRegression(max_iter=1000000), \n",
    "        'param_grid' : {\n",
    " #               'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2, 5, 10],\n",
    "                'vect__max_df': [.8, .85, .9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)],\n",
    "                'logistic_regression_tvec_no_ss__C' : np.logspace(-4,4,9), \n",
    "                'logistic_regression_tvec_no_ss__penalty' : ['l1', 'l2']\n",
    "               # 'logistic_regression_tvec__C' : np.logspace(-1,1,3)\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        'name': 'extratrees_tvec', \n",
    "        'vect': TfidfVectorizer(stop_words='english'), \n",
    "        'model': ExtraTreesClassifier(random_state = 42), \n",
    "        'param_grid' : {\n",
    "#                'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2, 5, 10],\n",
    "                'vect__max_df': [.8, .85, .9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)],\n",
    "                'extratrees_tvec__n_estimators' : [10, 50, 100, 200, 500],\n",
    "                'extratrees_tvec__max_depth': [3, 10, 100, 500]\n",
    "        }\n",
    "    }, \n",
    "    \n",
    "    \n",
    "    {\n",
    "        'name': 'random_forest_cvec', \n",
    "        'vect': CountVectorizer(stop_words='english'), \n",
    "        'model': RandomForestClassifier(random_state = 42), \n",
    "        'param_grid' : {\n",
    " #               'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2, 5, 10],\n",
    "                'vect__max_df': [.8, .85, .9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)], \n",
    "                'random_forest_cvec__n_estimators' : [10, 50, 100, 200, 500],\n",
    "                'random_forest_cvec__max_depth': [3, 10, 100, 500]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "rf_pipe = [{\n",
    "        'name': 'random_forest_cvec', \n",
    "        'vect': CountVectorizer(stop_words='english'), \n",
    "        'model': RandomForestClassifier(random_state = 42), \n",
    "        'param_grid' : {\n",
    " #               'vect__max_features': [None, 10000],\n",
    "                'vect__min_df': [1, 2, 5, 10],\n",
    "                'vect__max_df': [.8, .85, .9, 1.0],\n",
    "                'vect__ngram_range': [(1,1), (1,2)], \n",
    "                'random_forest_cvec__n_estimators' : [10, 50, 100, 200, 500],\n",
    "                'random_forest_cvec__max_depth': [3, 10, 100, 500]\n",
    "        }\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'naive_bayes_cvec__alpha': 0.6666666666666666, 'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.892644983320503\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 329\n",
      "True Negatives: 326\n",
      "False Positives: 33\n",
      "False Negatives: 33\n",
      "\n",
      "\n",
      "Accuracy: 0.9084604715672677\n",
      "Sensitivity/Recall (TPR): 0.9088397790055248\n",
      "Specificity (TNR): 0.9080779944289693\n",
      "Precision: 0.9088397790055248\n",
      "F1 Score: 0.9088397790055248\n",
      "\n",
      "======================\n",
      "\n",
      "Fitting 5 folds for each of 1800 candidates, totalling 9000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   46.3s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   60.0s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done 413 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=4)]: Done 473 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done 537 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=4)]: Done 570 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=4)]: Done 605 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=4)]: Done 677 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=4)]: Done 714 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=4)]: Done 753 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=4)]: Done 833 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=4)]: Done 917 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=4)]: Done 960 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=4)]: Done 1050 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=4)]: Done 1097 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=4)]: Done 1193 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=4)]: Done 1293 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=4)]: Done 1344 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=4)]: Done 1397 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=4)]: Done 1505 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=4)]: Done 1560 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=4)]: Done 1617 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=4)]: Done 1674 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=4)]: Done 1733 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=4)]: Done 1853 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=4)]: Done 1914 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=4)]: Done 1977 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=4)]: Done 2040 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=4)]: Done 2105 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=4)]: Done 2237 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=4)]: Done 2304 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=4)]: Done 2373 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 22.1min\n",
      "[Parallel(n_jobs=4)]: Done 2513 tasks      | elapsed: 22.7min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=4)]: Done 2657 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=4)]: Done 2730 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=4)]: Done 2805 tasks      | elapsed: 25.3min\n",
      "[Parallel(n_jobs=4)]: Done 2880 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=4)]: Done 2957 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=4)]: Done 3034 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=4)]: Done 3113 tasks      | elapsed: 27.7min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=4)]: Done 3273 tasks      | elapsed: 28.9min\n",
      "[Parallel(n_jobs=4)]: Done 3354 tasks      | elapsed: 29.6min\n",
      "[Parallel(n_jobs=4)]: Done 3437 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=4)]: Done 3520 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=4)]: Done 3605 tasks      | elapsed: 31.8min\n",
      "[Parallel(n_jobs=4)]: Done 3690 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=4)]: Done 3777 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=4)]: Done 3864 tasks      | elapsed: 34.0min\n",
      "[Parallel(n_jobs=4)]: Done 3953 tasks      | elapsed: 34.7min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed: 35.5min\n",
      "[Parallel(n_jobs=4)]: Done 4133 tasks      | elapsed: 36.2min\n",
      "[Parallel(n_jobs=4)]: Done 4224 tasks      | elapsed: 36.8min\n",
      "[Parallel(n_jobs=4)]: Done 4317 tasks      | elapsed: 37.6min\n",
      "[Parallel(n_jobs=4)]: Done 4410 tasks      | elapsed: 38.4min\n",
      "[Parallel(n_jobs=4)]: Done 4505 tasks      | elapsed: 39.3min\n",
      "[Parallel(n_jobs=4)]: Done 4600 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=4)]: Done 4697 tasks      | elapsed: 41.0min\n",
      "[Parallel(n_jobs=4)]: Done 4794 tasks      | elapsed: 41.9min\n",
      "[Parallel(n_jobs=4)]: Done 4893 tasks      | elapsed: 42.7min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed: 43.5min\n",
      "[Parallel(n_jobs=4)]: Done 5093 tasks      | elapsed: 44.5min\n",
      "[Parallel(n_jobs=4)]: Done 5194 tasks      | elapsed: 45.3min\n",
      "[Parallel(n_jobs=4)]: Done 5297 tasks      | elapsed: 46.3min\n",
      "[Parallel(n_jobs=4)]: Done 5400 tasks      | elapsed: 47.1min\n",
      "[Parallel(n_jobs=4)]: Done 5505 tasks      | elapsed: 47.8min\n",
      "[Parallel(n_jobs=4)]: Done 5610 tasks      | elapsed: 48.6min\n",
      "[Parallel(n_jobs=4)]: Done 5717 tasks      | elapsed: 49.5min\n",
      "[Parallel(n_jobs=4)]: Done 5824 tasks      | elapsed: 50.2min\n",
      "[Parallel(n_jobs=4)]: Done 5933 tasks      | elapsed: 51.0min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed: 51.8min\n",
      "[Parallel(n_jobs=4)]: Done 6153 tasks      | elapsed: 52.6min\n",
      "[Parallel(n_jobs=4)]: Done 6264 tasks      | elapsed: 53.5min\n",
      "[Parallel(n_jobs=4)]: Done 6377 tasks      | elapsed: 54.3min\n",
      "[Parallel(n_jobs=4)]: Done 6490 tasks      | elapsed: 55.2min\n",
      "[Parallel(n_jobs=4)]: Done 6605 tasks      | elapsed: 56.1min\n",
      "[Parallel(n_jobs=4)]: Done 6720 tasks      | elapsed: 57.2min\n",
      "[Parallel(n_jobs=4)]: Done 6837 tasks      | elapsed: 57.9min\n",
      "[Parallel(n_jobs=4)]: Done 6954 tasks      | elapsed: 58.7min\n",
      "[Parallel(n_jobs=4)]: Done 7073 tasks      | elapsed: 59.7min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed: 61.0min\n",
      "[Parallel(n_jobs=4)]: Done 7313 tasks      | elapsed: 61.9min\n",
      "[Parallel(n_jobs=4)]: Done 7434 tasks      | elapsed: 63.0min\n",
      "[Parallel(n_jobs=4)]: Done 7557 tasks      | elapsed: 64.1min\n",
      "[Parallel(n_jobs=4)]: Done 7680 tasks      | elapsed: 65.6min\n",
      "[Parallel(n_jobs=4)]: Done 7805 tasks      | elapsed: 66.6min\n",
      "[Parallel(n_jobs=4)]: Done 7930 tasks      | elapsed: 67.8min\n",
      "[Parallel(n_jobs=4)]: Done 8057 tasks      | elapsed: 69.1min\n",
      "[Parallel(n_jobs=4)]: Done 8184 tasks      | elapsed: 70.3min\n",
      "[Parallel(n_jobs=4)]: Done 8313 tasks      | elapsed: 71.6min\n",
      "[Parallel(n_jobs=4)]: Done 8442 tasks      | elapsed: 73.0min\n",
      "[Parallel(n_jobs=4)]: Done 8573 tasks      | elapsed: 74.0min\n",
      "[Parallel(n_jobs=4)]: Done 8704 tasks      | elapsed: 75.6min\n",
      "[Parallel(n_jobs=4)]: Done 8837 tasks      | elapsed: 77.0min\n",
      "[Parallel(n_jobs=4)]: Done 8970 tasks      | elapsed: 78.2min\n",
      "[Parallel(n_jobs=4)]: Done 9000 out of 9000 | elapsed: 78.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.svm._classes.SVC'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'svm_tvec__C': 2.223, 'svm_tvec__gamma': 'scale', 'svm_tvec__kernel': 'rbf', 'vect__max_df': 0.85, 'vect__min_df': 1, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8944957659738261\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 322\n",
      "True Negatives: 335\n",
      "False Positives: 24\n",
      "False Negatives: 40\n",
      "\n",
      "\n",
      "Accuracy: 0.9112343966712899\n",
      "Sensitivity/Recall (TPR): 0.8895027624309392\n",
      "Specificity (TNR): 0.9331476323119777\n",
      "Precision: 0.930635838150289\n",
      "F1 Score: 0.9096045197740112\n",
      "\n",
      "======================\n",
      "\n",
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed:   49.7s\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed:   57.5s\n",
      "[Parallel(n_jobs=4)]: Done 413 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 473 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 537 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 570 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 605 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 677 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 714 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 753 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 833 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done 917 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 960 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 1050 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 1097 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done 1193 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done 1293 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 1344 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done 1397 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 1505 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=4)]: Done 1560 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=4)]: Done 1617 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done 1674 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done 1733 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=4)]: Done 1853 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=4)]: Done 1914 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=4)]: Done 1977 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=4)]: Done 2040 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=4)]: Done 2105 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=4)]: Done 2237 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=4)]: Done 2304 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=4)]: Done 2373 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=4)]: Done 2513 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=4)]: Done 2657 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=4)]: Done 2730 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=4)]: Done 2805 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=4)]: Done 2880 out of 2880 | elapsed: 19.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'logistic_regression_cvec__C': 0.01, 'logistic_regression_cvec__penalty': 'l2', 'vect__max_df': 0.8, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.834339449148918\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 328\n",
      "True Negatives: 297\n",
      "False Positives: 62\n",
      "False Negatives: 34\n",
      "\n",
      "\n",
      "Accuracy: 0.8668515950069348\n",
      "Sensitivity/Recall (TPR): 0.9060773480662984\n",
      "Specificity (TNR): 0.8272980501392758\n",
      "Precision: 0.841025641025641\n",
      "F1 Score: 0.8723404255319149\n",
      "\n",
      "======================\n",
      "\n",
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:   56.4s\n",
      "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=4)]: Done 413 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 473 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 537 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 570 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 605 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 677 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 714 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 753 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 833 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done 917 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done 960 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 1050 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 1097 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 1193 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done 1293 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done 1344 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 1397 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 1505 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=4)]: Done 1560 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done 1617 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 1674 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=4)]: Done 1733 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=4)]: Done 1853 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=4)]: Done 1914 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done 1977 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=4)]: Done 2040 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=4)]: Done 2105 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done 2237 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=4)]: Done 2304 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=4)]: Done 2373 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=4)]: Done 2513 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=4)]: Done 2657 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=4)]: Done 2730 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=4)]: Done 2805 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=4)]: Done 2880 out of 2880 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'logistic_regression_tvec_no_ss__C': 1.0, 'logistic_regression_tvec_no_ss__penalty': 'l2', 'vect__max_df': 0.8, 'vect__min_df': 1, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8940338722093919\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 327\n",
      "True Negatives: 324\n",
      "False Positives: 35\n",
      "False Negatives: 35\n",
      "\n",
      "\n",
      "Accuracy: 0.9029126213592233\n",
      "Sensitivity/Recall (TPR): 0.9033149171270718\n",
      "Specificity (TNR): 0.9025069637883009\n",
      "Precision: 0.9033149171270718\n",
      "F1 Score: 0.9033149171270718\n",
      "\n",
      "======================\n",
      "\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 413 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 473 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done 537 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 570 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 605 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 677 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done 714 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done 753 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done 833 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=4)]: Done 917 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=4)]: Done 960 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=4)]: Done 1050 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=4)]: Done 1097 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=4)]: Done 1193 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=4)]: Done 1293 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=4)]: Done 1344 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=4)]: Done 1397 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=4)]: Done 1505 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=4)]: Done 1560 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=4)]: Done 1617 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=4)]: Done 1674 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=4)]: Done 1733 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=4)]: Done 1853 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=4)]: Done 1914 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=4)]: Done 1977 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=4)]: Done 2040 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=4)]: Done 2105 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=4)]: Done 2237 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=4)]: Done 2304 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=4)]: Done 2373 tasks      | elapsed: 28.1min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=4)]: Done 2513 tasks      | elapsed: 30.4min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=4)]: Done 2657 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=4)]: Done 2730 tasks      | elapsed: 33.2min\n",
      "[Parallel(n_jobs=4)]: Done 2805 tasks      | elapsed: 35.0min\n",
      "[Parallel(n_jobs=4)]: Done 2880 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=4)]: Done 2957 tasks      | elapsed: 41.6min\n",
      "[Parallel(n_jobs=4)]: Done 3034 tasks      | elapsed: 44.9min\n",
      "[Parallel(n_jobs=4)]: Done 3113 tasks      | elapsed: 52.3min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed: 59.6min\n",
      "[Parallel(n_jobs=4)]: Done 3200 out of 3200 | elapsed: 60.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Score Report =======\n",
      "\n",
      "Model: <class 'sklearn.ensemble._forest.ExtraTreesClassifier'>\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "\n",
      "\n",
      "Best Parameters: {'extratrees_tvec__max_depth': 500, 'extratrees_tvec__n_estimators': 200, 'vect__max_df': 0.8, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "******** Cross-Validation Scores ********\n",
      "Mean 5-fold CV accuracy: 0.8708878624583013\n",
      " \n",
      "******** Test/Validation Scores ********\n",
      "True Positives: 320\n",
      "True Negatives: 328\n",
      "False Positives: 31\n",
      "False Negatives: 42\n",
      "\n",
      "\n",
      "Accuracy: 0.8987517337031901\n",
      "Sensitivity/Recall (TPR): 0.8839779005524862\n",
      "Specificity (TNR): 0.9136490250696379\n",
      "Precision: 0.9116809116809117\n",
      "F1 Score: 0.8976157082748949\n",
      "\n",
      "======================\n",
      "\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0350s.) Setting batch_size=2.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter random_forest_tvec for estimator Pipeline(memory=None,\n         steps=[('vect',\n                 CountVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n                                 input='content', lowercase=True, max_df=1.0,\n                                 max_features=None, min_df=1,\n                                 ngram_range=(1, 1), preprocessor=None,\n                                 stop_words='english', strip_accents=None,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=None, vocabular...\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='gini',\n                                        max_depth=None, max_features='auto',\n                                        max_leaf_nodes=None, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1, min_samples_split=2,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=100, n_jobs=None,\n                                        oob_score=False, random_state=42,\n                                        verbose=0, warm_start=False))],\n         verbose=False). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 504, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/pipeline.py\", line 163, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\", line 50, in _set_params\n    super().set_params(**params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/base.py\", line 236, in set_params\n    (key, self))\nValueError: Invalid parameter random_forest_tvec for estimator Pipeline(memory=None,\n         steps=[('vect',\n                 CountVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n                                 input='content', lowercase=True, max_df=1.0,\n                                 max_features=None, min_df=1,\n                                 ngram_range=(1, 1), preprocessor=None,\n                                 stop_words='english', strip_accents=None,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=None, vocabular...\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='gini',\n                                        max_depth=None, max_features='auto',\n                                        max_leaf_nodes=None, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1, min_samples_split=2,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=100, n_jobs=None,\n                                        oob_score=False, random_state=42,\n                                        verbose=0, warm_start=False))],\n         verbose=False). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-259-554b9c16cd98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhyperparam_search_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe_gridsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipelines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-254-711d0e091514>\u001b[0m in \u001b[0;36mpipe_gridsearch\u001b[0;34m(pipelines, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter random_forest_tvec for estimator Pipeline(memory=None,\n         steps=[('vect',\n                 CountVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n                                 input='content', lowercase=True, max_df=1.0,\n                                 max_features=None, min_df=1,\n                                 ngram_range=(1, 1), preprocessor=None,\n                                 stop_words='english', strip_accents=None,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=None, vocabular...\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='gini',\n                                        max_depth=None, max_features='auto',\n                                        max_leaf_nodes=None, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1, min_samples_split=2,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=100, n_jobs=None,\n                                        oob_score=False, random_state=42,\n                                        verbose=0, warm_start=False))],\n         verbose=False). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "hyperparam_search_scores = pipe_gridsearch(pipelines, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
    "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.7s\n",
    "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    4.3s\n",
    "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    5.7s\n",
    "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    6.8s\n",
    "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    8.1s\n",
    "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   10.0s\n",
    "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   11.7s\n",
    "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   13.3s\n",
    "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   15.9s\n",
    "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   17.8s\n",
    "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   21.0s\n",
    "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   24.7s\n",
    "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:   28.6s\n",
    "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   32.5s\n",
    "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:   38.9s\n",
    "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   42.6s\n",
    "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:   46.1s\n",
    "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:   49.9s\n",
    "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:   54.7s\n",
    "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   57.9s\n",
    "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed:  1.0min\n",
    "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed:  1.1min\n",
    "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  1.2min\n",
    "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed:  1.2min\n",
    "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:  1.3min finished\n",
    "======== Score Report =======\n",
    "\n",
    "Model: <class 'sklearn.naive_bayes.MultinomialNB'>\n",
    "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
    "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
    "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
    "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                tokenizer=None, vocabulary=None)\n",
    "\n",
    "\n",
    "Best Parameters: {'naive_bayes_cvec__alpha': 0.6666666666666666, 'vect__max_df': 0.9, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
    "\n",
    "******** Cross-Validation Scores ********\n",
    "Mean 5-fold CV accuracy: 0.892644983320503\n",
    " \n",
    "******** Test/Validation Scores ********\n",
    "True Positives: 329\n",
    "True Negatives: 326\n",
    "False Positives: 33\n",
    "False Negatives: 33\n",
    "\n",
    "\n",
    "Accuracy: 0.9084604715672677\n",
    "Sensitivity/Recall (TPR): 0.9088397790055248\n",
    "Specificity (TNR): 0.9080779944289693\n",
    "Precision: 0.9088397790055248\n",
    "F1 Score: 0.9088397790055248\n",
    "\n",
    "======================\n",
    "\n",
    "Fitting 5 folds for each of 1800 candidates, totalling 9000 fits\n",
    "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    5.3s\n",
    "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    8.7s\n",
    "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:   13.1s\n",
    "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   17.8s\n",
    "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   21.8s\n",
    "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   29.5s\n",
    "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   34.4s\n",
    "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   39.5s\n",
    "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   46.3s\n",
    "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   52.2s\n",
    "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   60.0s\n",
    "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.1min\n",
    "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:  1.3min\n",
    "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.5min\n",
    "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:  1.7min\n",
    "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.9min\n",
    "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:  2.1min\n",
    "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:  2.3min\n",
    "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:  2.5min\n",
    "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  2.7min\n",
    "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed:  3.0min\n",
    "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed:  3.3min\n",
    "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.6min\n",
    "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed:  3.9min\n",
    "[Parallel(n_jobs=4)]: Done 413 tasks      | elapsed:  4.2min\n",
    "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  4.5min\n",
    "[Parallel(n_jobs=4)]: Done 473 tasks      | elapsed:  4.8min\n",
    "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  5.1min\n",
    "[Parallel(n_jobs=4)]: Done 537 tasks      | elapsed:  5.5min\n",
    "[Parallel(n_jobs=4)]: Done 570 tasks      | elapsed:  5.8min\n",
    "[Parallel(n_jobs=4)]: Done 605 tasks      | elapsed:  6.1min\n",
    "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  6.4min\n",
    "[Parallel(n_jobs=4)]: Done 677 tasks      | elapsed:  6.8min\n",
    "[Parallel(n_jobs=4)]: Done 714 tasks      | elapsed:  7.1min\n",
    "[Parallel(n_jobs=4)]: Done 753 tasks      | elapsed:  7.5min\n",
    "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  7.9min\n",
    "[Parallel(n_jobs=4)]: Done 833 tasks      | elapsed:  8.3min\n",
    "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  8.9min\n",
    "[Parallel(n_jobs=4)]: Done 917 tasks      | elapsed:  9.4min\n",
    "[Parallel(n_jobs=4)]: Done 960 tasks      | elapsed:  9.8min\n",
    "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed: 10.2min\n",
    "[Parallel(n_jobs=4)]: Done 1050 tasks      | elapsed: 10.6min\n",
    "[Parallel(n_jobs=4)]: Done 1097 tasks      | elapsed: 11.0min\n",
    "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed: 11.4min\n",
    "[Parallel(n_jobs=4)]: Done 1193 tasks      | elapsed: 11.7min\n",
    "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed: 12.1min\n",
    "[Parallel(n_jobs=4)]: Done 1293 tasks      | elapsed: 12.5min\n",
    "[Parallel(n_jobs=4)]: Done 1344 tasks      | elapsed: 12.9min\n",
    "[Parallel(n_jobs=4)]: Done 1397 tasks      | elapsed: 13.3min\n",
    "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed: 13.8min\n",
    "[Parallel(n_jobs=4)]: Done 1505 tasks      | elapsed: 14.2min\n",
    "[Parallel(n_jobs=4)]: Done 1560 tasks      | elapsed: 14.6min\n",
    "[Parallel(n_jobs=4)]: Done 1617 tasks      | elapsed: 15.1min\n",
    "[Parallel(n_jobs=4)]: Done 1674 tasks      | elapsed: 15.5min\n",
    "[Parallel(n_jobs=4)]: Done 1733 tasks      | elapsed: 16.1min\n",
    "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 16.5min\n",
    "[Parallel(n_jobs=4)]: Done 1853 tasks      | elapsed: 17.0min\n",
    "[Parallel(n_jobs=4)]: Done 1914 tasks      | elapsed: 17.5min\n",
    "[Parallel(n_jobs=4)]: Done 1977 tasks      | elapsed: 18.0min\n",
    "[Parallel(n_jobs=4)]: Done 2040 tasks      | elapsed: 18.6min\n",
    "[Parallel(n_jobs=4)]: Done 2105 tasks      | elapsed: 19.1min\n",
    "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed: 19.7min\n",
    "[Parallel(n_jobs=4)]: Done 2237 tasks      | elapsed: 20.4min\n",
    "[Parallel(n_jobs=4)]: Done 2304 tasks      | elapsed: 20.9min\n",
    "[Parallel(n_jobs=4)]: Done 2373 tasks      | elapsed: 21.5min\n",
    "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 22.1min\n",
    "[Parallel(n_jobs=4)]: Done 2513 tasks      | elapsed: 22.7min\n",
    "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed: 23.4min\n",
    "[Parallel(n_jobs=4)]: Done 2657 tasks      | elapsed: 24.0min\n",
    "[Parallel(n_jobs=4)]: Done 2730 tasks      | elapsed: 24.6min\n",
    "[Parallel(n_jobs=4)]: Done 2805 tasks      | elapsed: 25.3min\n",
    "[Parallel(n_jobs=4)]: Done 2880 tasks      | elapsed: 25.9min\n",
    "[Parallel(n_jobs=4)]: Done 2957 tasks      | elapsed: 26.5min\n",
    "[Parallel(n_jobs=4)]: Done 3034 tasks      | elapsed: 27.1min\n",
    "[Parallel(n_jobs=4)]: Done 3113 tasks      | elapsed: 27.7min\n",
    "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed: 28.3min\n",
    "[Parallel(n_jobs=4)]: Done 3273 tasks      | elapsed: 28.9min\n",
    "[Parallel(n_jobs=4)]: Done 3354 tasks      | elapsed: 29.6min\n",
    "[Parallel(n_jobs=4)]: Done 3437 tasks      | elapsed: 30.3min\n",
    "[Parallel(n_jobs=4)]: Done 3520 tasks      | elapsed: 31.1min\n",
    "[Parallel(n_jobs=4)]: Done 3605 tasks      | elapsed: 31.8min\n",
    "[Parallel(n_jobs=4)]: Done 3690 tasks      | elapsed: 32.6min\n",
    "[Parallel(n_jobs=4)]: Done 3777 tasks      | elapsed: 33.3min\n",
    "[Parallel(n_jobs=4)]: Done 3864 tasks      | elapsed: 34.0min\n",
    "[Parallel(n_jobs=4)]: Done 3953 tasks      | elapsed: 34.7min\n",
    "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed: 35.5min\n",
    "[Parallel(n_jobs=4)]: Done 4133 tasks      | elapsed: 36.2min\n",
    "[Parallel(n_jobs=4)]: Done 4224 tasks      | elapsed: 36.8min\n",
    "[Parallel(n_jobs=4)]: Done 4317 tasks      | elapsed: 37.6min\n",
    "[Parallel(n_jobs=4)]: Done 4410 tasks      | elapsed: 38.4min\n",
    "[Parallel(n_jobs=4)]: Done 4505 tasks      | elapsed: 39.3min\n",
    "[Parallel(n_jobs=4)]: Done 4600 tasks      | elapsed: 40.2min\n",
    "[Parallel(n_jobs=4)]: Done 4697 tasks      | elapsed: 41.0min\n",
    "[Parallel(n_jobs=4)]: Done 4794 tasks      | elapsed: 41.9min\n",
    "[Parallel(n_jobs=4)]: Done 4893 tasks      | elapsed: 42.7min\n",
    "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed: 43.5min\n",
    "[Parallel(n_jobs=4)]: Done 5093 tasks      | elapsed: 44.5min\n",
    "[Parallel(n_jobs=4)]: Done 5194 tasks      | elapsed: 45.3min\n",
    "[Parallel(n_jobs=4)]: Done 5297 tasks      | elapsed: 46.3min\n",
    "[Parallel(n_jobs=4)]: Done 5400 tasks      | elapsed: 47.1min\n",
    "[Parallel(n_jobs=4)]: Done 5505 tasks      | elapsed: 47.8min\n",
    "[Parallel(n_jobs=4)]: Done 5610 tasks      | elapsed: 48.6min\n",
    "[Parallel(n_jobs=4)]: Done 5717 tasks      | elapsed: 49.5min\n",
    "[Parallel(n_jobs=4)]: Done 5824 tasks      | elapsed: 50.2min\n",
    "[Parallel(n_jobs=4)]: Done 5933 tasks      | elapsed: 51.0min\n",
    "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed: 51.8min\n",
    "[Parallel(n_jobs=4)]: Done 6153 tasks      | elapsed: 52.6min\n",
    "[Parallel(n_jobs=4)]: Done 6264 tasks      | elapsed: 53.5min\n",
    "[Parallel(n_jobs=4)]: Done 6377 tasks      | elapsed: 54.3min\n",
    "[Parallel(n_jobs=4)]: Done 6490 tasks      | elapsed: 55.2min\n",
    "[Parallel(n_jobs=4)]: Done 6605 tasks      | elapsed: 56.1min\n",
    "[Parallel(n_jobs=4)]: Done 6720 tasks      | elapsed: 57.2min\n",
    "[Parallel(n_jobs=4)]: Done 6837 tasks      | elapsed: 57.9min\n",
    "[Parallel(n_jobs=4)]: Done 6954 tasks      | elapsed: 58.7min\n",
    "[Parallel(n_jobs=4)]: Done 7073 tasks      | elapsed: 59.7min\n",
    "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed: 61.0min\n",
    "[Parallel(n_jobs=4)]: Done 7313 tasks      | elapsed: 61.9min\n",
    "[Parallel(n_jobs=4)]: Done 7434 tasks      | elapsed: 63.0min\n",
    "[Parallel(n_jobs=4)]: Done 7557 tasks      | elapsed: 64.1min\n",
    "[Parallel(n_jobs=4)]: Done 7680 tasks      | elapsed: 65.6min\n",
    "[Parallel(n_jobs=4)]: Done 7805 tasks      | elapsed: 66.6min\n",
    "[Parallel(n_jobs=4)]: Done 7930 tasks      | elapsed: 67.8min\n",
    "[Parallel(n_jobs=4)]: Done 8057 tasks      | elapsed: 69.1min\n",
    "[Parallel(n_jobs=4)]: Done 8184 tasks      | elapsed: 70.3min\n",
    "[Parallel(n_jobs=4)]: Done 8313 tasks      | elapsed: 71.6min\n",
    "[Parallel(n_jobs=4)]: Done 8442 tasks      | elapsed: 73.0min\n",
    "[Parallel(n_jobs=4)]: Done 8573 tasks      | elapsed: 74.0min\n",
    "[Parallel(n_jobs=4)]: Done 8704 tasks      | elapsed: 75.6min\n",
    "[Parallel(n_jobs=4)]: Done 8837 tasks      | elapsed: 77.0min\n",
    "[Parallel(n_jobs=4)]: Done 8970 tasks      | elapsed: 78.2min\n",
    "[Parallel(n_jobs=4)]: Done 9000 out of 9000 | elapsed: 78.5min finished\n",
    "======== Score Report =======\n",
    "\n",
    "Model: <class 'sklearn.svm._classes.SVC'>\n",
    "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
    "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
    "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
    "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
    "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                tokenizer=None, use_idf=True, vocabulary=None)\n",
    "\n",
    "\n",
    "Best Parameters: {'svm_tvec__C': 2.223, 'svm_tvec__gamma': 'scale', 'svm_tvec__kernel': 'rbf', 'vect__max_df': 0.85, 'vect__min_df': 1, 'vect__ngram_range': (1, 2)}\n",
    "\n",
    "******** Cross-Validation Scores ********\n",
    "Mean 5-fold CV accuracy: 0.8944957659738261\n",
    " \n",
    "******** Test/Validation Scores ********\n",
    "True Positives: 322\n",
    "True Negatives: 335\n",
    "False Positives: 24\n",
    "False Negatives: 40\n",
    "\n",
    "\n",
    "Accuracy: 0.9112343966712899\n",
    "Sensitivity/Recall (TPR): 0.8895027624309392\n",
    "Specificity (TNR): 0.9331476323119777\n",
    "Precision: 0.930635838150289\n",
    "F1 Score: 0.9096045197740112\n",
    "\n",
    "======================\n",
    "\n",
    "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
    "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.5s\n",
    "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.2s\n",
    "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    2.1s\n",
    "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    2.6s\n",
    "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    4.4s\n",
    "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.7s\n",
    "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    7.1s\n",
    "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    8.4s\n",
    "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   10.3s\n",
    "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   11.7s\n",
    "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   13.2s\n",
    "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   15.2s\n",
    "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:   17.4s\n",
    "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   19.3s\n",
    "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:   22.3s\n",
    "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   25.4s\n",
    "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:   29.2s\n",
    "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:   32.2s\n",
    "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:   36.9s\n",
    "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   40.7s\n",
    "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed:   45.6s\n",
    "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed:   49.7s\n",
    "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:   53.5s\n",
    "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed:   57.5s\n",
    "[Parallel(n_jobs=4)]: Done 413 tasks      | elapsed:  1.0min\n",
    "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.1min\n",
    "[Parallel(n_jobs=4)]: Done 473 tasks      | elapsed:  1.2min\n",
    "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  1.3min\n",
    "[Parallel(n_jobs=4)]: Done 537 tasks      | elapsed:  1.4min\n",
    "[Parallel(n_jobs=4)]: Done 570 tasks      | elapsed:  1.5min\n",
    "[Parallel(n_jobs=4)]: Done 605 tasks      | elapsed:  1.6min\n",
    "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  1.7min\n",
    "[Parallel(n_jobs=4)]: Done 677 tasks      | elapsed:  1.7min\n",
    "[Parallel(n_jobs=4)]: Done 714 tasks      | elapsed:  1.8min\n",
    "[Parallel(n_jobs=4)]: Done 753 tasks      | elapsed:  1.9min\n",
    "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  2.0min\n",
    "[Parallel(n_jobs=4)]: Done 833 tasks      | elapsed:  2.2min\n",
    "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  2.3min\n",
    "[Parallel(n_jobs=4)]: Done 917 tasks      | elapsed:  2.5min\n",
    "[Parallel(n_jobs=4)]: Done 960 tasks      | elapsed:  2.6min\n",
    "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed:  2.7min\n",
    "[Parallel(n_jobs=4)]: Done 1050 tasks      | elapsed:  2.8min\n",
    "[Parallel(n_jobs=4)]: Done 1097 tasks      | elapsed:  2.9min\n",
    "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed:  3.1min\n",
    "[Parallel(n_jobs=4)]: Done 1193 tasks      | elapsed:  3.3min\n",
    "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  3.5min\n",
    "[Parallel(n_jobs=4)]: Done 1293 tasks      | elapsed:  3.7min\n",
    "[Parallel(n_jobs=4)]: Done 1344 tasks      | elapsed:  3.9min\n",
    "[Parallel(n_jobs=4)]: Done 1397 tasks      | elapsed:  4.0min\n",
    "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:  4.2min\n",
    "[Parallel(n_jobs=4)]: Done 1505 tasks      | elapsed:  4.6min\n",
    "[Parallel(n_jobs=4)]: Done 1560 tasks      | elapsed:  4.9min\n",
    "[Parallel(n_jobs=4)]: Done 1617 tasks      | elapsed:  5.1min\n",
    "[Parallel(n_jobs=4)]: Done 1674 tasks      | elapsed:  5.3min\n",
    "[Parallel(n_jobs=4)]: Done 1733 tasks      | elapsed:  5.5min\n",
    "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  6.0min\n",
    "[Parallel(n_jobs=4)]: Done 1853 tasks      | elapsed:  6.6min\n",
    "[Parallel(n_jobs=4)]: Done 1914 tasks      | elapsed:  7.1min\n",
    "[Parallel(n_jobs=4)]: Done 1977 tasks      | elapsed:  7.3min\n",
    "[Parallel(n_jobs=4)]: Done 2040 tasks      | elapsed:  7.4min\n",
    "[Parallel(n_jobs=4)]: Done 2105 tasks      | elapsed:  8.1min\n",
    "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed:  9.3min\n",
    "[Parallel(n_jobs=4)]: Done 2237 tasks      | elapsed: 10.3min\n",
    "[Parallel(n_jobs=4)]: Done 2304 tasks      | elapsed: 10.5min\n",
    "[Parallel(n_jobs=4)]: Done 2373 tasks      | elapsed: 10.7min\n",
    "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 11.9min\n",
    "[Parallel(n_jobs=4)]: Done 2513 tasks      | elapsed: 14.2min\n",
    "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed: 15.5min\n",
    "[Parallel(n_jobs=4)]: Done 2657 tasks      | elapsed: 15.7min\n",
    "[Parallel(n_jobs=4)]: Done 2730 tasks      | elapsed: 16.2min\n",
    "[Parallel(n_jobs=4)]: Done 2805 tasks      | elapsed: 18.0min\n",
    "[Parallel(n_jobs=4)]: Done 2880 out of 2880 | elapsed: 19.8min finished\n",
    "======== Score Report =======\n",
    "\n",
    "Model: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
    "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
    "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
    "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
    "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                tokenizer=None, vocabulary=None)\n",
    "\n",
    "\n",
    "Best Parameters: {'logistic_regression_cvec__C': 0.01, 'logistic_regression_cvec__penalty': 'l2', 'vect__max_df': 0.8, 'vect__min_df': 10, 'vect__ngram_range': (1, 1)}\n",
    "\n",
    "******** Cross-Validation Scores ********\n",
    "Mean 5-fold CV accuracy: 0.834339449148918\n",
    " \n",
    "******** Test/Validation Scores ********\n",
    "True Positives: 328\n",
    "True Negatives: 297\n",
    "False Positives: 62\n",
    "False Negatives: 34\n",
    "\n",
    "\n",
    "Accuracy: 0.8668515950069348\n",
    "Sensitivity/Recall (TPR): 0.9060773480662984\n",
    "Specificity (TNR): 0.8272980501392758\n",
    "Precision: 0.841025641025641\n",
    "F1 Score: 0.8723404255319149\n",
    "\n",
    "======================\n",
    "\n",
    "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
    "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.6s\n",
    "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.6s\n",
    "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    3.6s\n",
    "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    5.1s\n",
    "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    7.1s\n",
    "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    9.0s\n",
    "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   10.2s\n",
    "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   11.6s\n",
    "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   13.6s\n",
    "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   15.0s\n",
    "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   16.8s\n",
    "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   18.6s\n",
    "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:   20.9s\n",
    "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   23.0s\n",
    "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:   28.4s\n",
    "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   33.5s\n",
    "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:   36.6s\n",
    "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:   39.4s\n",
    "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:   43.1s\n",
    "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   46.5s\n",
    "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed:   50.0s\n",
    "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed:   53.2s\n",
    "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:   56.4s\n",
    "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed:   59.3s\n",
    "[Parallel(n_jobs=4)]: Done 413 tasks      | elapsed:  1.0min\n",
    "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.1min\n",
    "[Parallel(n_jobs=4)]: Done 473 tasks      | elapsed:  1.2min\n",
    "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  1.3min\n",
    "[Parallel(n_jobs=4)]: Done 537 tasks      | elapsed:  1.4min\n",
    "[Parallel(n_jobs=4)]: Done 570 tasks      | elapsed:  1.5min\n",
    "[Parallel(n_jobs=4)]: Done 605 tasks      | elapsed:  1.6min\n",
    "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  1.7min\n",
    "[Parallel(n_jobs=4)]: Done 677 tasks      | elapsed:  1.8min\n",
    "[Parallel(n_jobs=4)]: Done 714 tasks      | elapsed:  1.9min\n",
    "[Parallel(n_jobs=4)]: Done 753 tasks      | elapsed:  1.9min\n",
    "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  2.0min\n",
    "[Parallel(n_jobs=4)]: Done 833 tasks      | elapsed:  2.1min\n",
    "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  2.2min\n",
    "[Parallel(n_jobs=4)]: Done 917 tasks      | elapsed:  2.3min\n",
    "[Parallel(n_jobs=4)]: Done 960 tasks      | elapsed:  2.5min\n",
    "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed:  2.5min\n",
    "[Parallel(n_jobs=4)]: Done 1050 tasks      | elapsed:  2.6min\n",
    "[Parallel(n_jobs=4)]: Done 1097 tasks      | elapsed:  2.7min\n",
    "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed:  2.8min\n",
    "[Parallel(n_jobs=4)]: Done 1193 tasks      | elapsed:  3.0min\n",
    "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  3.1min\n",
    "[Parallel(n_jobs=4)]: Done 1293 tasks      | elapsed:  3.2min\n",
    "[Parallel(n_jobs=4)]: Done 1344 tasks      | elapsed:  3.4min\n",
    "[Parallel(n_jobs=4)]: Done 1397 tasks      | elapsed:  3.5min\n",
    "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:  3.7min\n",
    "[Parallel(n_jobs=4)]: Done 1505 tasks      | elapsed:  3.8min\n",
    "[Parallel(n_jobs=4)]: Done 1560 tasks      | elapsed:  4.0min\n",
    "[Parallel(n_jobs=4)]: Done 1617 tasks      | elapsed:  4.2min\n",
    "[Parallel(n_jobs=4)]: Done 1674 tasks      | elapsed:  4.3min\n",
    "[Parallel(n_jobs=4)]: Done 1733 tasks      | elapsed:  4.4min\n",
    "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  4.6min\n",
    "[Parallel(n_jobs=4)]: Done 1853 tasks      | elapsed:  4.9min\n",
    "[Parallel(n_jobs=4)]: Done 1914 tasks      | elapsed:  5.1min\n",
    "[Parallel(n_jobs=4)]: Done 1977 tasks      | elapsed:  5.2min\n",
    "[Parallel(n_jobs=4)]: Done 2040 tasks      | elapsed:  5.4min\n",
    "[Parallel(n_jobs=4)]: Done 2105 tasks      | elapsed:  5.6min\n",
    "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed:  5.9min\n",
    "[Parallel(n_jobs=4)]: Done 2237 tasks      | elapsed:  6.2min\n",
    "[Parallel(n_jobs=4)]: Done 2304 tasks      | elapsed:  6.4min\n",
    "[Parallel(n_jobs=4)]: Done 2373 tasks      | elapsed:  6.6min\n",
    "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  6.9min\n",
    "[Parallel(n_jobs=4)]: Done 2513 tasks      | elapsed:  7.4min\n",
    "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed:  7.7min\n",
    "[Parallel(n_jobs=4)]: Done 2657 tasks      | elapsed:  7.8min\n",
    "[Parallel(n_jobs=4)]: Done 2730 tasks      | elapsed:  8.1min\n",
    "[Parallel(n_jobs=4)]: Done 2805 tasks      | elapsed:  8.7min\n",
    "[Parallel(n_jobs=4)]: Done 2880 out of 2880 | elapsed:  9.5min finished\n",
    "======== Score Report =======\n",
    "\n",
    "Model: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
    "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
    "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
    "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
    "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
    "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                tokenizer=None, use_idf=True, vocabulary=None)\n",
    "\n",
    "\n",
    "Best Parameters: {'logistic_regression_tvec_no_ss__C': 1.0, 'logistic_regression_tvec_no_ss__penalty': 'l2', 'vect__max_df': 0.8, 'vect__min_df': 1, 'vect__ngram_range': (1, 1)}\n",
    "\n",
    "******** Cross-Validation Scores ********\n",
    "Mean 5-fold CV accuracy: 0.8940338722093919\n",
    " \n",
    "******** Test/Validation Scores ********\n",
    "True Positives: 327\n",
    "True Negatives: 324\n",
    "False Positives: 35\n",
    "False Negatives: 35\n",
    "\n",
    "\n",
    "Accuracy: 0.9029126213592233\n",
    "Sensitivity/Recall (TPR): 0.9033149171270718\n",
    "Specificity (TNR): 0.9025069637883009\n",
    "Precision: 0.9033149171270718\n",
    "F1 Score: 0.9033149171270718\n",
    "\n",
    "======================\n",
    "\n",
    "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n",
    "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.8s\n",
    "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.4s\n",
    "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    4.4s\n",
    "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    5.5s\n",
    "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    7.5s\n",
    "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    9.6s\n",
    "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   12.3s\n",
    "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   13.9s\n",
    "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   17.6s\n",
    "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   19.9s\n",
    "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   22.7s\n",
    "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   25.4s\n",
    "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:   29.1s\n",
    "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   32.8s\n",
    "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:   37.6s\n",
    "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   43.9s\n",
    "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:   48.5s\n",
    "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:   53.7s\n",
    "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:   59.3s\n",
    "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  1.1min\n",
    "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed:  1.2min\n",
    "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed:  1.3min\n",
    "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  1.4min\n",
    "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed:  1.6min\n",
    "[Parallel(n_jobs=4)]: Done 413 tasks      | elapsed:  1.7min\n",
    "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.9min\n",
    "[Parallel(n_jobs=4)]: Done 473 tasks      | elapsed:  2.1min\n",
    "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  2.3min\n",
    "[Parallel(n_jobs=4)]: Done 537 tasks      | elapsed:  2.6min\n",
    "[Parallel(n_jobs=4)]: Done 570 tasks      | elapsed:  2.8min\n",
    "[Parallel(n_jobs=4)]: Done 605 tasks      | elapsed:  3.0min\n",
    "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  3.3min\n",
    "[Parallel(n_jobs=4)]: Done 677 tasks      | elapsed:  3.9min\n",
    "[Parallel(n_jobs=4)]: Done 714 tasks      | elapsed:  4.4min\n",
    "[Parallel(n_jobs=4)]: Done 753 tasks      | elapsed:  4.9min\n",
    "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  5.3min\n",
    "[Parallel(n_jobs=4)]: Done 833 tasks      | elapsed:  5.4min\n",
    "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  5.6min\n",
    "[Parallel(n_jobs=4)]: Done 917 tasks      | elapsed:  5.7min\n",
    "[Parallel(n_jobs=4)]: Done 960 tasks      | elapsed:  5.9min\n",
    "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed:  6.2min\n",
    "[Parallel(n_jobs=4)]: Done 1050 tasks      | elapsed:  6.4min\n",
    "[Parallel(n_jobs=4)]: Done 1097 tasks      | elapsed:  6.6min\n",
    "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed:  6.9min\n",
    "[Parallel(n_jobs=4)]: Done 1193 tasks      | elapsed:  7.1min\n",
    "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  7.4min\n",
    "[Parallel(n_jobs=4)]: Done 1293 tasks      | elapsed:  7.6min\n",
    "[Parallel(n_jobs=4)]: Done 1344 tasks      | elapsed:  8.1min\n",
    "[Parallel(n_jobs=4)]: Done 1397 tasks      | elapsed:  8.5min\n",
    "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:  8.9min\n",
    "[Parallel(n_jobs=4)]: Done 1505 tasks      | elapsed:  9.6min\n",
    "[Parallel(n_jobs=4)]: Done 1560 tasks      | elapsed: 10.4min\n",
    "[Parallel(n_jobs=4)]: Done 1617 tasks      | elapsed: 11.1min\n",
    "[Parallel(n_jobs=4)]: Done 1674 tasks      | elapsed: 11.3min\n",
    "[Parallel(n_jobs=4)]: Done 1733 tasks      | elapsed: 11.5min\n",
    "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 11.8min\n",
    "[Parallel(n_jobs=4)]: Done 1853 tasks      | elapsed: 12.3min\n",
    "[Parallel(n_jobs=4)]: Done 1914 tasks      | elapsed: 12.8min\n",
    "[Parallel(n_jobs=4)]: Done 1977 tasks      | elapsed: 13.6min\n",
    "[Parallel(n_jobs=4)]: Done 2040 tasks      | elapsed: 14.3min\n",
    "[Parallel(n_jobs=4)]: Done 2105 tasks      | elapsed: 15.6min\n",
    "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed: 17.6min\n",
    "[Parallel(n_jobs=4)]: Done 2237 tasks      | elapsed: 19.0min\n",
    "[Parallel(n_jobs=4)]: Done 2304 tasks      | elapsed: 23.1min\n",
    "[Parallel(n_jobs=4)]: Done 2373 tasks      | elapsed: 28.1min\n",
    "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 30.0min\n",
    "[Parallel(n_jobs=4)]: Done 2513 tasks      | elapsed: 30.4min\n",
    "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed: 31.1min\n",
    "[Parallel(n_jobs=4)]: Done 2657 tasks      | elapsed: 32.0min\n",
    "[Parallel(n_jobs=4)]: Done 2730 tasks      | elapsed: 33.2min\n",
    "[Parallel(n_jobs=4)]: Done 2805 tasks      | elapsed: 35.0min\n",
    "[Parallel(n_jobs=4)]: Done 2880 tasks      | elapsed: 37.2min\n",
    "[Parallel(n_jobs=4)]: Done 2957 tasks      | elapsed: 41.6min\n",
    "[Parallel(n_jobs=4)]: Done 3034 tasks      | elapsed: 44.9min\n",
    "[Parallel(n_jobs=4)]: Done 3113 tasks      | elapsed: 52.3min\n",
    "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed: 59.6min\n",
    "[Parallel(n_jobs=4)]: Done 3200 out of 3200 | elapsed: 60.1min finished\n",
    "======== Score Report =======\n",
    "\n",
    "Model: <class 'sklearn.ensemble._forest.ExtraTreesClassifier'>\n",
    "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
    "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
    "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
    "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
    "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                tokenizer=None, use_idf=True, vocabulary=None)\n",
    "\n",
    "\n",
    "Best Parameters: {'extratrees_tvec__max_depth': 500, 'extratrees_tvec__n_estimators': 200, 'vect__max_df': 0.8, 'vect__min_df': 2, 'vect__ngram_range': (1, 1)}\n",
    "\n",
    "******** Cross-Validation Scores ********\n",
    "Mean 5-fold CV accuracy: 0.8708878624583013\n",
    " \n",
    "******** Test/Validation Scores ********\n",
    "True Positives: 320\n",
    "True Negatives: 328\n",
    "False Positives: 31\n",
    "False Negatives: 42\n",
    "\n",
    "\n",
    "Accuracy: 0.8987517337031901\n",
    "Sensitivity/Recall (TPR): 0.8839779005524862\n",
    "Specificity (TNR): 0.9136490250696379\n",
    "Precision: 0.9116809116809117\n",
    "F1 Score: 0.8976157082748949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:   47.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   55.7s\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done 413 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 473 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done 537 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 570 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done 605 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=4)]: Done 677 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=4)]: Done 714 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=4)]: Done 753 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=4)]: Done 833 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=4)]: Done 917 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=4)]: Done 960 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=4)]: Done 1050 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=4)]: Done 1097 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=4)]: Done 1193 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=4)]: Done 1293 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=4)]: Done 1344 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=4)]: Done 1397 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=4)]: Done 1505 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=4)]: Done 1560 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=4)]: Done 1617 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=4)]: Done 1674 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=4)]: Done 1733 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=4)]: Done 1853 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=4)]: Done 1914 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=4)]: Done 1977 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=4)]: Done 2040 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=4)]: Done 2105 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=4)]: Done 2237 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=4)]: Done 2304 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=4)]: Done 2373 tasks      | elapsed: 24.2min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=4)]: Done 2513 tasks      | elapsed: 25.2min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=4)]: Done 2657 tasks      | elapsed: 26.0min\n",
      "[Parallel(n_jobs=4)]: Done 2730 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=4)]: Done 2805 tasks      | elapsed: 27.4min\n",
      "[Parallel(n_jobs=4)]: Done 2880 tasks      | elapsed: 28.4min\n",
      "[Parallel(n_jobs=4)]: Done 2957 tasks      | elapsed: 30.1min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-2691d7e0fa49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhyperparam_search_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe_gridsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-254-711d0e091514>\u001b[0m in \u001b[0;36mpipe_gridsearch\u001b[0;34m(pipelines, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparam_search_scores = pipe_gridsearch(rf_pipe, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
